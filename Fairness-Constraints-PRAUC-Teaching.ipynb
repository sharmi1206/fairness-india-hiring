{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4vFDhvn_Bdn"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Constrained Optimization Authors. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpUmH2nk_Bdo"
   },
   "source": [
    "## PR-AUC , ROC-AUC, Precision at Recall, Recall at Precision Maximization\n",
    "In this colab, we'll show how to use the TF Constrained Optimization (TFCO) library to train a model to maximize the *Area Under the Precision-Recall Curve (PR-AUC)*. We'll show how to train the model both with (i) plain TensorFlow (in eager mode), and (ii) with a custom tf.Estimator.\n",
    "\n",
    "We start by importing the relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-constrained-optimization\n",
      "  Using cached tensorflow_constrained_optimization-0.2-py2.py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow-constrained-optimization) (1.15.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow-constrained-optimization) (1.5.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow-constrained-optimization) (1.18.5)\n",
      "Requirement already satisfied: tensorflow>=1.14 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow-constrained-optimization) (2.3.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (1.32.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (3.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (0.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow>=1.14->tensorflow-constrained-optimization) (1.11.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.22.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.7.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (49.2.0.post20200714)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (2.10)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (1.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.14->tensorflow-constrained-optimization) (3.1.0)\n",
      "Installing collected packages: tensorflow-constrained-optimization\n",
      "Successfully installed tensorflow-constrained-optimization-0.2\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow constrained optimization library\n",
    "!pip install tensorflow-constrained-optimization\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoYVEXPA_Bdp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import tensorflow.compat.v2 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ea1KIDRgC4eq"
   },
   "outputs": [],
   "source": [
    "import tensorflow_constrained_optimization as tfco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLxZD5uH_Bds"
   },
   "source": [
    "## Staffing\n",
    "\n",
    "We will use the School Staffing dataset from the Indian Human Development Survey - II  (School Staffing and Medical Staffing) repository for our illustration. This dataset contains various demographic, religion and racial distribution details (aggregated from human development survey related data sources) about different communities in the India, along with the their age, position and level of education.\n",
    "\n",
    "\n",
    "We begin by downloading and preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "gJ_JcV-V_Bdu",
    "outputId": "f0ac9073-186e-47ca-c8ab-85d8012ec0ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DISTID</th>\n",
       "      <th>PSUID</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>SQGOVT</th>\n",
       "      <th>SS1</th>\n",
       "      <th>SS3</th>\n",
       "      <th>SS4</th>\n",
       "      <th>SS5</th>\n",
       "      <th>SS6</th>\n",
       "      <th>SS7</th>\n",
       "      <th>SS8</th>\n",
       "      <th>SS9</th>\n",
       "      <th>SS10</th>\n",
       "      <th>SS11</th>\n",
       "      <th>SS12</th>\n",
       "      <th>SS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEID  DISTID  PSUID  SCHOOLID  SQGOVT SS1 SS3 SS4 SS5 SS6 SS7 SS8 SS9  \\\n",
       "0        1       2      1         1       1   1   1   1   5   1   1  25  15   \n",
       "1        1       2      1         1       1   2   2   3   5   1   2  26  15   \n",
       "2        1       2      1         1       1   3   3   3  99   1   2  35   0   \n",
       "3        1       2      1         2       2   1   1   3   2   2   2  25  15   \n",
       "4        1       2      1         2       2   2   2   1   2   1   2  21  15   \n",
       "\n",
       "  SS10 SS11 SS12 SS13  \n",
       "0    1    2    3    2  \n",
       "1    1    2    3    2  \n",
       "2         2    5    0  \n",
       "3    0    2    3    4  \n",
       "4    0    2    3    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"data/staffing-teaching/School-Staff-Data.csv\"\n",
    "\n",
    "# Read dataset from  https://www.researchconnections.org/icpsrweb/instructors/studies/36151 repository and assign column names.\n",
    "data_df = pd.read_csv(dataset_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgoeyhS0_Bds"
   },
   "outputs": [],
   "source": [
    "# List of column names in the dataset.\n",
    "cols = data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS1\n",
      "{'1': 1.0, '2': 12.0, '3': 23.0, '4': 34.0, '5': 42.0, '6': 43.0, '7': 44.0, '8': 45.0, '9': 46.0, '10': 2.0, '11': 3.0, '12': 4.0, '13': 5.0, '14': 6.0, '15': 7.0, '16': 8.0, '17': 9.0, '18': 10.0, '19': 11.0, '20': 13.0, '21': 14.0, '22': 15.0, '23': 16.0, '24': 17.0, '25': 18.0, '26': 19.0, '27': 20.0, '28': 21.0, '29': 22.0, '30': 24.0, '31': 25.0, '32': 26.0, '33': 27.0, '34': 28.0, '35': 29.0, '36': 30.0, '37': 31.0, '38': 32.0, '39': 33.0, '40': 35.0, '41': 36.0, '42': 37.0, '43': 38.0, '44': 39.0, '45': 40.0, '46': 41.0, ' ': 0.0}\n",
      "SS3\n",
      "{'1': 1.0, '2': 2.0, '3': 3.0, '5': 5.0, '4': 4.0, ' ': 0.0}\n",
      "SS4\n",
      "{'1': 1.0, '3': 3.0, '2': 2.0, ' ': 0.0}\n",
      "SS5\n",
      "{'5': 9.0, '99': 15.0, '2': 5.0, '4': 8.0, '3': 7.0, '8': 13.0, '6': 11.0, '1': 1.0, '10': 2.0, '55': 10.0, '12': 4.0, '9': 14.0, '7': 12.0, ' ': 0.0, '11': 3.0, '22': 6.0}\n",
      "SS6\n",
      "{'1': 1.0, '2': 2.0, ' ': 0.0, '3': 3.0}\n",
      "SS7\n",
      "{'1': 1.0, '2': 2.0, ' ': 0.0}\n",
      "SS8\n",
      "{'25': 12.0, '26': 13.0, '35': 22.0, '21': 8.0, '32': 19.0, '27': 14.0, '24': 11.0, '34': 21.0, '44': 31.0, '30': 17.0, '28': 15.0, '48': 35.0, '63': 50.0, '55': 42.0, '42': 29.0, '33': 20.0, '37': 24.0, '40': 27.0, '72': 59.0, '39': 26.0, '43': 30.0, '22': 9.0, '51': 38.0, '36': 23.0, '45': 32.0, '47': 34.0, '29': 16.0, '65': 52.0, '23': 10.0, '20': 7.0, '19': 6.0, '56': 43.0, '50': 37.0, '52': 39.0, '57': 44.0, '53': 40.0, '31': 18.0, '49': 36.0, '46': 33.0, '58': 45.0, '38': 25.0, '18': 5.0, '61': 48.0, '60': 47.0, '62': 49.0, '41': 28.0, '54': 41.0, '68': 55.0, '80': 66.0, '67': 54.0, '59': 46.0, '70': 57.0, '76': 63.0, '71': 58.0, '66': 53.0, '74': 61.0, '17': 4.0, ' ': 0.0, '75': 62.0, '16': 3.0, '73': 60.0, '15': 2.0, '64': 51.0, '8': 65.0, '69': 56.0, '79': 64.0, '82': 67.0, '14': 1.0}\n",
      "SS9\n",
      "{'15': 4.0, '0': 1.0, '17': 5.0, '12': 3.0, '10': 2.0, '5': 6.0, '8': 7.0, ' ': 0.0}\n",
      "SS10\n",
      "{'1': 2.0, ' ': 0.0, '0': 1.0}\n",
      "SS11\n",
      "{'2': 2.0, '1': 1.0, '3': 3.0, ' ': 0.0, '4': 4.0, '5': 5.0, '6': 6.0, '9': 9.0, '8': 8.0, '7': 7.0}\n",
      "SS12\n",
      "{'3': 3.0, '5': 5.0, '2': 2.0, ' ': 0.0, '6': 6.0, '1': 1.0, '4': 4.0}\n",
      "SS13\n",
      "{'2': 13.0, '0': 1.0, '4': 35.0, '1': 2.0, '5': 43.0, '12': 5.0, '35': 30.0, '3': 24.0, '7': 57.0, '10': 3.0, '8': 62.0, '9': 66.0, '21': 15.0, '14': 7.0, '11': 4.0, '13': 6.0, '6': 51.0, ' ': 0.0, '80': 63.0, '45': 39.0, '17': 10.0, '60': 52.0, '18': 11.0, '90': 67.0, '20': 14.0, '25': 19.0, '15': 8.0, '30': 25.0, '16': 9.0, '40': 36.0, '26': 20.0, '22': 16.0, '31': 26.0, '50': 44.0, '99': 68.0, '33': 28.0, '28': 22.0, '19': 12.0, '23': 17.0, '27': 21.0, '82': 64.0, '24': 18.0, '38': 33.0, '46': 40.0, '39': 34.0, '75': 61.0, '70': 58.0, '56': 49.0, '63': 54.0, '32': 27.0, '34': 29.0, '55': 48.0, '42': 37.0, '37': 32.0, '36': 31.0, '54': 47.0, '65': 55.0, '48': 42.0, '73': 60.0, '47': 41.0, '53': 46.0, '72': 59.0, '52': 45.0, '85': 65.0, '58': 50.0, '62': 53.0, '43': 38.0, '66': 56.0, '29': 23.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DISTID</th>\n",
       "      <th>PSUID</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>SQGOVT</th>\n",
       "      <th>SS1</th>\n",
       "      <th>SS3</th>\n",
       "      <th>SS4</th>\n",
       "      <th>SS5</th>\n",
       "      <th>SS6</th>\n",
       "      <th>SS7</th>\n",
       "      <th>SS8</th>\n",
       "      <th>SS9</th>\n",
       "      <th>SS10</th>\n",
       "      <th>SS11</th>\n",
       "      <th>SS12</th>\n",
       "      <th>SS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEID  DISTID  PSUID  SCHOOLID  SQGOVT   SS1  SS3  SS4   SS5  SS6  SS7  \\\n",
       "0        1       2      1         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "1        1       2      1         1       1  12.0  2.0  3.0   9.0  1.0  2.0   \n",
       "2        1       2      1         1       1  23.0  3.0  3.0  15.0  1.0  2.0   \n",
       "3        1       2      1         2       2   1.0  1.0  3.0   5.0  2.0  2.0   \n",
       "4        1       2      1         2       2  12.0  2.0  1.0   5.0  1.0  2.0   \n",
       "5        1       2      2         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "6        1       2      2         1       1  12.0  2.0  2.0   9.0  1.0  2.0   \n",
       "7        1       2      2         2       2   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "8        1       2      2         2       2  12.0  2.0  3.0   9.0  1.0  1.0   \n",
       "9        1       2      2         2       2  23.0  2.0  3.0   9.0  1.0  1.0   \n",
       "\n",
       "    SS8  SS9  SS10  SS11  SS12  SS13  \n",
       "0  12.0  4.0   2.0   2.0   3.0  13.0  \n",
       "1  13.0  4.0   2.0   2.0   3.0  13.0  \n",
       "2  22.0  1.0   0.0   2.0   5.0   1.0  \n",
       "3  12.0  4.0   1.0   2.0   3.0  35.0  \n",
       "4   8.0  4.0   1.0   2.0   3.0   2.0  \n",
       "5  22.0  5.0   2.0   2.0   2.0  43.0  \n",
       "6  19.0  5.0   2.0   2.0   2.0   2.0  \n",
       "7  14.0  4.0   2.0   2.0   2.0   1.0  \n",
       "8  11.0  4.0   2.0   2.0   2.0   1.0  \n",
       "9  21.0  3.0   1.0   2.0   2.0   1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data_df.select_dtypes(include=[object]):\n",
    "\n",
    "    data_df['org_'+col] =  data_df[col]\n",
    "    data_df[col] = data_df[col].astype('category').cat.codes\n",
    "    data_df[col] = data_df[col].astype(float)\n",
    "    print(col)\n",
    "    print(dict(zip( data_df['org_'+ col], data_df[col] ) ))\n",
    "\n",
    "\n",
    "data_df = data_df[cols]\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['SS9'] = data_df['SS9'].astype(int)\n",
    "data_df['SS9'] = np.where((data_df['SS9'] != 5), 0, 1)\n",
    "data_df['SS9'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJtOkt90_Bdy"
   },
   "outputs": [],
   "source": [
    "labels_df = data_df['SS9'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "31989    0\n",
       "31990    0\n",
       "31991    0\n",
       "31992    0\n",
       "31993    0\n",
       "Name: SS9, Length: 31994, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543898"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8-rQaGH_Bd2"
   },
   "source": [
    "We encode all categorical columns, and use other numerical/boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEID', 'DISTID', 'PSUID', 'SCHOOLID', 'SQGOVT', 'SS1', 'SS3', 'SS4',\n",
       "       'SS5', 'SS6', 'SS7', 'SS8', 'SS9', 'SS10', 'SS11', 'SS12', 'SS13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eJcNA1B_Bd5"
   },
   "source": [
    "Some of the numerical columns contain missing values (denoted by a NaN). For each feature that has at least one value missing, we append an additional boolean \"is_missing\" feature indicating that the value was missing, and fill the missing value with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_RgukXn_Bd5"
   },
   "outputs": [],
   "source": [
    "feature_names = data_df.columns\n",
    "for feature_name in feature_names:  \n",
    "    # Which rows have missing values?\n",
    "    missing_rows = data_df[feature_name].isna()\n",
    "    if missing_rows.any():  # Check if at least one row has a missing value.\n",
    "        data_df[feature_name].fillna(0.0, inplace=True)  # Fill NaN with 0.\n",
    "        missing_rows.rename(feature_name + \"_is_missing\", inplace=True)\n",
    "        data_df = data_df.join(missing_rows)  # Append \"is_missing\" feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8U5yENt_Bd-"
   },
   "source": [
    "Finally, we divide the dataset randomly into two-thirds for training and one-thirds for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bixDM2G0Bspg"
   },
   "outputs": [],
   "source": [
    "# Set random seed so that the results are reproducible.\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Train and test indices.\n",
    "train_indices, test_indices = model_selection.train_test_split(\n",
    "    np.arange(data_df.shape[0]), test_size=1./3.)\n",
    "\n",
    "# Train and test data.\n",
    "x_train_df = data_df.loc[train_indices].astype(np.float32)\n",
    "y_train_df = labels_df.loc[train_indices].astype(np.float32)\n",
    "x_test_df = data_df.loc[test_indices].astype(np.float32)\n",
    "y_test_df = labels_df.loc[test_indices].astype(np.float32)\n",
    "\n",
    "# Convert data frames to NumPy arrays.\n",
    "x_train = x_train_df.values\n",
    "y_train = y_train_df.values\n",
    "x_test = x_test_df.values\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXyyoSrG_BeA"
   },
   "source": [
    "# (1a)  PR-AUC Training with Plain TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoqCCpf0oTIY"
   },
   "outputs": [],
   "source": [
    "batch_size = 128  # first fix the batch size for mini-batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqo2mpRi_BeA"
   },
   "source": [
    "\n",
    "We will work with a linear classification model and define the data and model tensors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1fxMQmy_BeB"
   },
   "outputs": [],
   "source": [
    "# Create linear Keras model.\n",
    "layers = []\n",
    "layers.append(tf.keras.Input(shape=(x_train.shape[-1],)))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(1))\n",
    "model = tf.keras.Sequential(layers)\n",
    "\n",
    "# Create nullary functions that return labels and logits from the current\n",
    "# batch. In eager mode, TFCO requires these to be provided via nullary function.\n",
    "# We will maintain a running array of batch indices.\n",
    "batch_indices = np.arange(batch_size)\n",
    "labels_fn = lambda: tf.constant(y_train[batch_indices], dtype=tf.float32)\n",
    "logits_fn = lambda: model(x_train[batch_indices, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmFBVhsQ_BeD"
   },
   "source": [
    "We next set up the constraint optimization problem to optimize PR-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Swn_y0T_BeD"
   },
   "outputs": [],
   "source": [
    "# Create context with labels and predictions.\n",
    "context = tfco.rate_context(logits_fn, labels_fn)\n",
    "\n",
    "# Create optimization problem with PR-AUC as the objective. The library\n",
    "# expects a minimization objective, so we negate the PR-AUC. \n",
    "\n",
    "# We use the pr_auc rate helper which uses a Riemann approximation to the area \n",
    "# under the precision-recall curve (recall on the horizontal axis, precision on \n",
    "# the vertical axis). We would need to specify the the number of bins \n",
    "# (\"rectangles\") to use for the Riemann approximation. We also can optionally\n",
    "# specify the surrogate to be used to approximate the PR-AUC.\n",
    "pr_auc_rate = tfco.pr_auc(\n",
    "    context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "problem = tfco.RateMinimizationProblem(-pr_auc_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwpTHgqg_BeG"
   },
   "source": [
    "We then create a loss function from the `problem` and optimize it to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkq2aVIn_BeG"
   },
   "outputs": [],
   "source": [
    "# Create Lagrangian loss for `problem`. What we get back is a loss function, a \n",
    "# a nullary function that returns a list of update_ops that need to be run \n",
    "# before every gradient update, and the Lagrange multiplier variables internally\n",
    "# maintained by the loss function. The argument `dual_scale` is a \n",
    "# hyper-parameter that specifies the relative importance placed on updates on \n",
    "# the Lagrange multipliers.\n",
    "loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "    problem, dual_scale=1.0)\n",
    "\n",
    "# Set up optimizer and the list of variables to optimize.\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "var_list = (model.trainable_weights + problem.trainable_variables + \n",
    "            [multipliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ra-Cog9C_BeI"
   },
   "source": [
    "Before proceeding to solving the training problem, we write an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFUyqbVx_BeI"
   },
   "outputs": [],
   "source": [
    "def pr_auc(model, features, labels):\n",
    "    # Returns the PR-AUC for given model, features and binary labels.\n",
    "    scores = model.predict(features)\n",
    "    \n",
    "    print(len(scores), len(y_test))\n",
    "    y_pred = model.predict(x_test)\n",
    "    pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    precisions, recall, f1_score, true_sum = metrics.precision_recall_fscore_support(y_test, pred_labels)\n",
    "\n",
    "    accuracy_score = metrics.accuracy_score(y_test, pred_labels)\n",
    "    \n",
    "    return metrics.average_precision_score(labels,scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MID6ChJn_BeK"
   },
   "source": [
    "We are now ready to train our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "ZWUWtSp8NzK5",
    "outputId": "bd5488b6-030c-4cb7-e276-8788ec81a3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21329 10665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n",
      "21329 10665\n",
      "10665 10665\n"
     ]
    }
   ],
   "source": [
    "num_steps = 250\n",
    "num_examples = x_train.shape[0]\n",
    "\n",
    "train_objectives = []\n",
    "test_objectives = []\n",
    "\n",
    "for ii in range(num_steps):\n",
    "  # Indices for current batch; cycle back once we reach the end of stream.\n",
    "  batch_indices = np.arange(ii * batch_size, (ii + 1) * batch_size)\n",
    "  batch_indices = [ind % num_examples for ind in batch_indices]\n",
    "\n",
    "  # First run update ops, and then gradient update.\n",
    "  update_ops_fn()\n",
    "  optimizer.minimize(loss_fn, var_list=var_list)\n",
    "\n",
    "  # Record train and test objectives once every 10 steps.\n",
    "  if ii % 10 == 0:\n",
    "    train_objectives.append(pr_auc(model, x_train, y_train))\n",
    "    test_objectives.append(pr_auc(model, x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAD0CAYAAACGlm89AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hc1bX38e9Ssy2523LvDXcbI0wLLQSwKaEEEkpogTjcQBpJLibUhJBLGm8aCYEAhkAgEMA2YGIIAQwGFxn3LncV25K7JavOev+YkRkL2RrZI81o9Ps8jx7NnLNnZulIS+uUffY2d0dEREQSR1KsAxAREZHoUnEXERFJMCruIiIiCUbFXUREJMGouIuIiCQYFXcREZEEo+KegMzsLTO7IdZxiIhIbKi4xwkz2x/2FTCzA2HPr63Pe7n7RHd/5ijj2Bj22dvM7Gkzax1a976ZlYbWFZnZq2bWPYL3fN/MdplZi1qW31Jj2Vlmlhv23Mzsu2a2zMyKzSzXzF42s1FH8/OJxEo0czz0fp/Lnxrr+5mZh33GRjObHLbeQzm138zyzOwRM0uu4zMzQu1n1LLOzWxQjWUPmNlzYc/bmtnvzGxz6H1yQs871++nl7qouMcJd29d/QVsBi4OW/Z8dTszS2mEcC4OxTEOOBG4J2zd7aF1g4DWwG+O9EZm1g84HXDgy0cRy++B7wHfBToCQ4CpwIVH8V4iMRNpjjeA9qHPvBq4z8wmhK0bE1p3JvA14Bt1vNcVQBlwXiQ79uHMLA14FxgBTADaAqcCO4Dx9XkvqZuKe5yrPpI1szvNbCvwtJl1MLM3zKwwdET8hpn1CnvNwT16M7vRzD4ys9+E2m4ws4mRfLa75wFvASNrWbebYJEdW8fbXA/MAaYA9bpUYGaDgduAq939v+5e5u4l7v68uz9cn/cSiVdmlmRmk81snZntMLOXzKxjaF1LM3sutHy3mc03s65m9hDBneY/hY6A/1TX57j7J8Byas/nHGA2defzDcBjwBKgvmcbrgf6AJe5+wp3D7j7dnd/0N0/dyZAjo2Ke9PQjeBRa19gEsHf29Oh532AA8CRkvskYDXQGfgV8KSZWV0fama9gQuAhbWs6wRcDuTU8TbXA8+Hvs43s651fW6Yc4Bcd59Xj9eINDXfBS4lePTcA9gFPBpadwPQDugNdAJuBQ64+93Ah4TOpLn77Uf6gNDlrdMIHjXXls9DCe4sHDafzawPcBaf5fP1kf+IAHwJ+Le776/n6+QoqLg3DQHg/tCR6wF33+Hur4SOYvcBDxH8x3A4m9z9CXevAp4BugNHKrJTzWw38BHwAfCLsHV/MLM9QBHBnYXvHO5NzOwLBHdAXnL3BcA64Jo6f9rPdAIK6tFepCn6FnC3u+e6exnwAHBF6BJcBcE8GOTuVe6+wN331vP9i4CdwN+Aye7+bti6T82sGFgJvA/8+Qjvcz2wxN1XAC8AI8zs+HrEoXxuRCruTUOhu5dWPzGzdDP7q5ltMrO9wCyg/RE6w2ytfuDuJaGHrY/weZe6e3t37+vu33b3A2Hrvuvu7YDRQAegVyimn4R13Hks1PYG4G13Lwo9/weHnpqvBFJrfHYqwX9oELwWV6/reiJNUF/gtdBp990EC20VwR3wvwMzgRfNLN/MfmVmNXOmLp3dvYO7D3P3P9RYN47g/4KvETzDlwEH77ip2dmv+iwc7p5PcMc/PJ+rUD7HDRX3pqHm1H0/BI4DTnL3tsAZoeV1nmqPWkDuS4GfA4+ambn7L8I6B91qZq2ArwJnmtnWUH+BHwBjzGxM6G02A/1qvHV/YFPo8btALzPLavAfSCR2tgATQzvU1V8t3T3P3Svc/afuPpxg57OL+Ox0eFSm9PSgl4BPgPtCyyaGd/Yzs1OBwcBdYfl8EnB1WCffuvL5PwQvzWVEI245MhX3pqkNwevsu0Mdb+6PURzPAF2ovRf8pQT35IcT7KQzFhhG8Dph9T+nfwI3mdn40DXBIQR3AF4EcPe1BE8TvhDqWJgW6mB0VfgtPSJN3GPAQ2bWF8DMMs3sktDjs81sVOis3F6CR8FVoddtAwZEMY6HgUlm1q2WdTcA73BoPo8E0oHqDrr/BO4xs16hToJfAi4G/hVa/3eCOzKvmNnQUJtOobN+F0Tx5xBU3Juq3wGtCF5LmwP8OxZBuHs58Afg3lpW3wA87e6b3X1r9RfBjn/XmlmKu88EJhPsHLgHmEFwh+HxsPf5bug1jwK7CV63vwx4vYF+LJHG9ntgOvC2me0jmNMnhdZ1I1gc9xI8Xf8B8FzY664I3QVT83R7vYXOxn0A/Dh8uZm1JHgW7o/huezuGwgW7OpT8z8DPibYV2cXwc6717r7stD7lxHsVLeK4I7CXmAewb47c481fjmUuUflzI6IiIjECR25i4iIJBgVdxERkQSj4i4iIpJgVNxFREQSTGNMQlKrzp07e79+/WL18SIJZ8GCBUXunhnrOJTbItF1NLkds+Ler18/srOzY/XxIgnHzDbV3arhKbdFoutoclun5UVERBKMiruIiEiCUXEXERFJMHUWdzN7ysy2m9myw6w3M/uDmeWY2RIzGxf9MEUk2pTbIokrkiP3KcCEI6yfSHC2oMHAJOAvxx6WiDSCKSi3RRJSncXd3WcBO4/Q5BLg2dC0gXMIziuuOXtF6sndCQSCX1Whr8qqAJVVARpiDgjltkjjqZnflVUBqgINN7dLNG6F60lwGr9quaFlBVF4b5GocHfKKgOUlFdRUl7JgfIqisMeVy8vLgt9L6+ipCz4vbSiivLKABVVASqqnPKq6scByisDVFY5Ve4E3AkECBZmd9yDSRxwgkntocfuuHPwNZHU7YX3nkuHjLSG31CHUm5L3AnP5QMVwfwsqwhQWhn2uKKK0spQXpdVUVxeeTDHw5+XVwaoDHjwqyqYy5WB0LKq6pwN5u0h+RzK20O+A4Q99oPfD/+zTBjRjceuO6FBtlM0irvVsqzWH8fMJhE8vUefPn2i8NHSHFUFnLxdB1hftJ8NRcXs2F/O/rJK9pVWsr+s4rPHpZXsK6ukpKySkoqqiIpotZQkI6NFChlpybRMTSYtJYnU5KTQd6N1ixRahJalJCeRbJBkRlKSkWxGUlLouRlJBklJwcfJSYZVtzVINgOzg0lkBtXPLLTQgJapyVHdhhFSbkuj2XOggpzt+8nZvo+c7fvZUFTC/rIKSsqrKC4L7nhXF+WjOeJtmZpERloKrdKSD35PS0miZWoSyUlJpCYZKclGSlISKcnBXE0J5a1V53FYDhvBZdX5TOi7wSHrgYM5XjO/B2a2jtr2qykaxT0X6B32vBeQX1tDd3+c0FzdWVlZmmtWDqu8MsC2vaXk7jrA5p3FrC8sZn1RMRuKitm8o4TyqsDBtslJwWLbukUKbVoGv3fMSKNPx3Rat0gho0UK6WnJtEpLJj01mfRQYh9clpZC6xbB7+mh52kpupEE5bZEmbuzbW8Z6wv3s65wP2u37ydne/B74b6yg+3SUpLo3ymDdumpdMpIo3fHdDJCuZkRlqutUoM73y1Tk2iRmkzLlODjlqHl6WnJB3M6Oam2fdXEFY3iPh243cxeBE4C9ri7TttJROZv3MmyvD3k7z5A/u5S8nYfoGDPAbbvKzvkSDstJYl+ndIZmJnBl4Z1ZUDnDPpnZtCvUwadW6dh1rwSt5Eot+WouDtrt+9n7bb9Bwv5+qJi1m3fT3F51cF2rVukMKhLa84cksmgLq0Z3KU1g7q0pleH9GZXjKOtzuJuZi8AZwGdzSwXuB9IBXD3x4AZwAVADlAC3NRQwUriKNpfxk9fX8Hri4MHgi1SkujZvhU92rfizCGZ9Ag97tGuFX07pdOjfSsle5Qpt6UhbCwq5p6py/gop+jgsp7tWzEgM4Mrs3ozMDODAZmtGZjZmq5tW2jHvIHUWdzd/eo61jtwW9QikoTm7kxdlMfPXl9BcVkVd5w7hGtO6kOnDB19NzbltkRTeWWAx2et4w//zaFFchL3XDiMUwZ2on/nDNLTYjaNSbOlLS6NJm/3Ae5+bSnvry5kXJ/2/PIroxnctU2swxKRYzR/405+8upS1m7fz4WjunPfxcPp2rZlrMNq1lTcpcEFAs5zczfxy7dW4cADFw/nulP66TS7SBO3p6SCh/+9khfmbaFn+1Y8eUMW5wzrGuuwBBV3aWA52/cz+ZUlZG/axemDO/OLy0bRu2N6rMMSkWPg7kxfnM+Db6xgV0kF3zy9Pz84d4hOv8cR/SakQewqLucP/13Lc3M2kZ6Wwm+vHMPl43rqurpIE7ckdzcPvbmSuRt2MqZXO6bcNJ6RPdvFOiypQcVdoqq0ooqnZ2/kz+/nUFxWyVezevPD844js02LWIcmIscgb/cBfjNzNa8tzKNjRhoPXjKCa07qq8trcUrFXaIiEHBeW5jHb99eTf6eUs4Z2oU7Jw5liDrMiTRp+0or+Mv763jyow048O2zBnLrWQNp2zI11qHJEai4yzH7aG0Rv5ixkhUFexnVsx2/+eoYTh3YOdZhicgxqKwK8ML8LfzunTXsKC7n0rE9+PGEofRs3yrWoUkEVNzlqJVWVHHb85/y7qrt9OrQit9fNZaLR/cgSafpRJq0lQV7uf0fn7KusJjx/Tvy9IXDGN2rfazDknpQcZej9sSs9by7ajs/Pv84bjm9Py1SYjK5iYhEUVXAueOlxew5UMlfrzuB84Z3VUfYJkjFXY7Klp0l/Om9HC4Y1Y3bzh4U63BEJEr+MW8zKwv28ug14zh/RLdYhyNHSVNfyVF58I0VJJlxz4XDYx2KiETJruJyfvv2ak4e0JELRqmwN2Uq7lJv76/eztsrtnH7FwfRQ51rRBLGI++sYe+BCh748gidim/iVNylXsoqq3hg+nIGdM7gltP7xzocEYmSFfl7eX7uJq47uS9Du7WNdThyjCIq7mY2wcxWm1mOmU2uZX0HM3vNzJaY2TwzGxn9UCUe/O3DDWzcUcIDXx6hDnRNnPJaqrk7D7y+nHatUrnj3ONiHY5EQZ3F3cySgUeBicBw4Gozq3mh9SfAIncfDVwP/D7agUrs5e0+wB//u5YJI7pxxpDMWIcjx0B5LeHeWFLAvA07+fH5Q2mXrsFpEkEkR+7jgRx3X+/u5cCLwCU12gwH3gVw91VAPzPT1EAJ5sHXVwBw78XqRJcAlNcCQEl5Jb+YsZIRPdrytRN7xzociZJIintPYEvY89zQsnCLgcsBzGw80BfoVfONzGySmWWbWXZhYeHRRSwxMWtNIf9evpXvfHGwRqhKDFHL69B65XYT9ef31lGwp5SffnmExolPIJEU99p+217j+cNABzNbBHwHWAhUfu5F7o+7e5a7Z2Vm6rRuU1Hdia6/OtElkqjlNSi3m6pNO4p5fNZ6Lh3bg6x+HWMdjkRRJIPY5ALh52p6AfnhDdx9L3ATgAXvn9gQ+pIE8ORHG1hfVMyUm05UJ7rEobwWfv7mSlKSjbsuGBbrUCTKIjlynw8MNrP+ZpYGXAVMD29gZu1D6wBuAWaF/jFIE5e/+wB/fDeH84Z35azjusQ6HIke5XUz98GaQt5ZsY3vfHEwXdu2jHU4EmV1Hrm7e6WZ3Q7MBJKBp9x9uZndGlr/GDAMeNbMqoAVwM0NGLM0oofeXInj3HuROtElEuV181ZeGeCnry+nX6d0vvGFfrEORxpARGPLu/sMYEaNZY+FPf4EGBzd0CTWFm3ZzZtLC7jj3CH07pge63AkypTXzddzczaxvrCYp27M0qW2BKUR6uSwnvxoA21apPCNL6gTnUiiKKus4q+z1nHygI58cajubExUKu5Sq/zdB5ixtICrxvemdQtNHiiSKKYtymfb3jL+5yzN5pjIVNylVs9+sgl354ZT+8U6FBGJkkDA+esH6xjWvS1nDO4c63CkAam4y+eUlFfywrzNTBzZnV4ddK1dJFG8u2o76wqLufXMAZr1LcGpuMvnvLIglz0HKtSLViTBPPbBOnq2b8WFo7rHOhRpYCrucohAwHlq9kbG9G7PuD4dYh2OiETJ/I07WbBpF988vT8pyfrXn+j0G5ZDvLd6OxuKirn5C/112k4kgfz1g3V0SE/lq5ocpllQcZdDPDV7A93btWTiyG6xDkVEomTNtn38Z+V2rj+lH+lpuvulOVBxl4NWFuxlds4Orj+lH6k6bSeSMB6ftZ6WqUm6+6UZ0X9wOeipjzbQKjWZa8b3iXUoIhIlBXsOMG1RHled2IeOGWl1v0ASgoq7AFC4r4xpi/K54oRetEtPjXU4IhIlT364gYDDzRppsllRcRcAnp+7ifKqADee1i/WoYhIlOwpqeCFeZu5aHR3zQ/RzKi4C6UVVTw3ZxNfHNqFgZmtYx2OiETJc3M3UVxexaQzBsQ6FGlkERV3M5tgZqvNLMfMJteyvp2ZvW5mi81suZndFP1QpaFMX5xP0f5ynbZrZpTXia20ooqnZ2/gjCGZjOjRLtbhSCOrs7ibWTLwKDARGA5cbWY1J/e+DVjh7mOAs4Dfmpl6bjQB7s5TH21gaLc2nDqwU6zDkUaivE58r3yaS9H+cm7VUXuzFMmR+3ggx93Xu3s58CJwSY02DrSx4KgnrYGdQGVUI5UG8cm6Hazauo9vnKZBa5oZ5XUCqwo4T8xaz+he7ThFO+3NUiTFvSewJex5bmhZuD8Bw4B8YCnwPXcP1HwjM5tkZtlmll1YWHiUIUs0PfnRBjplpPHlsT1iHYo0rqjlNSi3483M5VvZuKOEb50xUDvtzVQkxb22vwyv8fx8YBHQAxgL/MnM2n7uRe6Pu3uWu2dlZmbWO1iJro1Fxby7ajvXntyXlqnJsQ5HGlfU8hqU2/HmuTmb6N2xFRM00mSzFUlxzwXCByPuRXBPPtxNwKselANsAIZGJ0RpKC9lbyHJ4NqTNGhNM6S8TlBb95TyyfodXH58L5KTdNTeXEVS3OcDg82sf6gzzVXA9BptNgPnAJhZV+A4YH00A5Xoqgo4r36ax5lDMunatmWsw5HGp7xOUNMX5+EOlx5f8yqLNCd1ziDg7pVmdjswE0gGnnL35WZ2a2j9Y8CDwBQzW0rwdN+d7l7UgHHLMfoop4ite0u57+KaHaSlOVBeJ67XFuYzpnd7+nfOiHUoEkMRTQ/k7jOAGTWWPRb2OB84L7qhSUN6OXsL7dNTOWdYl1iHIjGivE48q7fuY2XBXh7QTnuzpxHqmqE9JRW8vWIbl47tSYsUdaQTSRRTF+WRnGRcNEZ3vzR3Ku7N0PTFeZRXBrjihF6xDkVEoiQQcKYtzOP0wZ3p3LpFrMORGFNxb4ZeXpDL0G5tGNGj1ruaRKQJmr9xJ/l7SrlMHekEFfdmZ/XWfSzJ3cOVWb01uIVIApm6KI/0tGTOHd411qFIHFBxb2Zezt5CSpJxqUakE0kYZZVVvLmkgPNHdCM9LaJ+0pLgVNybkYqqAFMX5XHOsC500jU5kYTx3qpC9pZW6t52OUjFvRl5b9V2ivaXc+UJvetuLCJNxtSFeXRuncZpmiRGQlTcm5F/Lcilc+sWnHWcxv4WSRR7Sir476rtXDymBynJ+pcuQfpLaCaK9pfx31XbuXxcT/0DEEkgby0roLwqoF7ycgj9l28mpi7MozLgXKl720USymsL8xjQOYNRPdvFOhSJIyruzYC7868FuYzp3Z7BXdvEOhwRiZK83QeYu2Enlx7fU7e2yiFU3JuBZXl7WbV1n47aRRLM9EXBWXovHatT8nIoFfdm4OUFW2iRksTFGm9aJKFMXZjHuD7t6dMpPdahSJyJqLib2QQzW21mOWY2uZb1PzazRaGvZWZWZWYdox+u1FdpRRXTFuVz/ohutGuVGutwJI4or5u2lQV7Wb1tnzrSSa3qLO5mlgw8CkwEhgNXm9kh8wm6+6/dfay7jwXuAj5w950NEbDUz39WbmPPgQquzNIpefmM8rrpm7owj5Qk48LROiMnnxfJkft4IMfd17t7OfAicMkR2l8NvBCN4OTY/WtBLj3ateTUgZ1jHYrEF+V1E1YVcKYtyufMIZl0zEiLdTgShyIp7j2BLWHPc0PLPsfM0oEJwCuHWT/JzLLNLLuwsLC+sUo95e8+wKw1hVw+rhfJSepJK4eIWl6H2ii3G9HcDTvYurdUw83KYUVS3GurCn6YthcDsw936s7dH3f3LHfPyszUKGkNqSrg/OjlxaSlJPG1EzXcrHxO1PIalNuNyd2ZMnsjGWnJfGmYZoCT2kVS3HOB8OrQC8g/TNur0Km7uPCn/+bw8bod/OySkfTuqJ608jnK6ybqbx9u4O0V2/j22YNolZYc63AkTkVS3OcDg82sv5mlEUz06TUbmVk74ExgWnRDlPr6eF0Rv393DZcf31P3tsvhKK+boFlrCvm/t1YycWQ3vn3WwFiHI3Gszol/3b3SzG4HZgLJwFPuvtzMbg2tfyzU9DLgbXcvbrBopU6F+8r43ouL6N85gwcvHalRq6RWyuumZ9OOYr7zwkIGd2nDb64co9yWI6qzuAO4+wxgRo1lj9V4PgWYEq3ApP4CAeeOlxax90AFf795PBktIvr1SjOlvG46issqmfTsAgAev/4E5bbUSX8hCeTP7+fw4doiHr58FEO7tY11OCISBe7BzrFrt+/jmW+Mp2+njFiHJE2Ahp9NEHPW7+CRd9Zwydge6h0vkkAefS+Ht5Zt5a6Jwzh9sO5EkMiouCeAHfvL+N6LC+nXKYOHLhula3EiCeLdldv4bWin/ZbT+8c6HGlCdFq+iQsEnB+8tJhdJRU8feN4WutanEhCWFe4n++/uIjh3dvy8OWjtdMu9aIj9ybuLx+sY9aaQu6/eDjDe+g6u0gi2FtawTefzSY1JYm/XneC7meXetNhXhO2NHcPj7yzhotGd+ea8X1iHY6IRMkD05azaUcJz99yEr06aBAqqT8duTdhf521jvS0ZH5xua6ziySKbXtLmbY4nxtP7cfJAzrFOhxpolTcm6iCPQd4a9lWrjqxN21bap52kUTx4rwtVAWc607uG+tQpAlTcW+inpuzCXfn+lP6xToUEYmSyqoAL8zbzOmDO9Ovs+5nl6On4t4ElVZU8Y+5m/nSsK6aFEYkgby7ajtb95bydR21yzFScW+Cpi/KZ1dJBTedpvteRRLJc3M20b1dS84Z2iXWoUgTp+LexLg7T3+8kaHd2nDygI6xDkdEomRjUTEfri3iqhP7kJKsf81ybCL6CzKzCWa22sxyzGzyYdqcZWaLzGy5mX0Q3TCl2twNO1lZsJcbT+2nHvJyTJTX8eUf8zaTnGRcNV7DR8uxq/M+dzNLBh4FzgVygflmNt3dV4S1aQ/8GZjg7pvNTOeUGsiU2Rtpn57Kpcf3jHUo0oQpr+NLaUUVL2dv4bzhXenatmWsw5EEEMmR+3ggx93Xu3s58CJwSY021wCvuvtmAHffHt0wBSB3Vwlvr9jK1eP70DJVI1bJMVFex5EZSwvYVVKhjnQSNZEU957AlrDnuaFl4YYAHczsfTNbYGbX1/ZGZjbJzLLNLLuwsPDoIm7G/v7JJsxM979KNEQtr0G5fayem7OJAZ0zOHWgBq2R6IikuNd2YddrPE8BTgAuBM4H7jWzIZ97kfvj7p7l7lmZmZq6sD5Kyit5Yd5mJozoRo/2rWIdjjR9UctrUG4fi+X5e/h0826uPbmv+tFI1EQytnwuEN7DoxeQX0ubIncvBorNbBYwBlgTlSiF1xbmsbe0khtP6xfrUCQxKK/jxHNzNtMyNYkrxvWKdSiSQCI5cp8PDDaz/maWBlwFTK/RZhpwupmlmFk6cBKwMrqhNl/uzpTZGxnZsy1ZfTvEOhxJDMrrOLCvtIJpi/K4eHQP2qVrGGmJnjqP3N290sxuB2YCycBT7r7czG4NrX/M3Vea2b+BJUAA+Ju7L2vIwJuT2Tk7WLt9P7+5coxO20lUKK/jw2sL8ygpr1JHOom6iKZ8dfcZwIwayx6r8fzXwK+jF5pUm/LxBjplpHHR6O6xDkUSiPI6ttyd5+ZsYlTPdozp3T7W4UiC0TBIcW7TjmLeXbWda0/S7W8iiWT+xl2s2bafr5/cJ9ahSAJScY9zz3y8iWQzrtVpO5GE8tycTbRpmcLFY3rEOhRJQCrucWx/WSUvZ2/hglHdNWqVSAIp2l/GW8sK+Mq4XqSnRXR1VKReVNzj2PRF+ewr0+1vIonmpewtVFS5TslLg1Fxj2PTF+cxIDOD49XZRiRhuDv/ys7lpP4dGdSlTazDkQSl4h6ntu0tZe6GnVw8uodufxNJIGu372d9UTEX6Vq7NCAV9zg1Y2kB7nDxGN3+JpJIZi7bihmcP7xrrEORBKbiHqfeWFLA0G5tdNpOJMHMXLGV43u3p4s6yUoDUnGPQ3m7D7Bg0y7dIiOSYLbsLGFZ3l7OH9Et1qFIglNxj0NvLgnO36ER6UQSy9srtgGouEuDU3GPQ28sKWB0r3b07ZQR61BEJIpmLt/K0G5t6NdZuS0NS8U9zmwsKmZJ7h4dtYskmKL9ZWRv3Ml5OmqXRqDiHmfeXFoAwIWjdb1dJJH8Z8U2Ag7nj1AveWl4ERV3M5tgZqvNLMfMJtey/iwz22Nmi0Jf90U/1Obh9cX5nNC3Az3bt4p1KJLglNeNa+byrfTq0Irh3dvGOhRpBuoc1NjMkoFHgXOBXGC+mU139xU1mn7o7hc1QIzNRs72fazauo/7Lx4e61AkwSmvG9e+0gpm5+zgulP6alAqaRSRHLmPB3Lcfb27lwMvApc0bFjN0+uLCzCDC0bpers0OOV1I3p/dSHlVQEmjNT1dmkckRT3nsCWsOe5oWU1nWJmi83sLTMbUdsbmdkkM8s2s+zCwsKjCLdpKS6rZHn+nojaujtvLMnnpP4dNQOcNIao5TU0r9wuq6ziqsc/4dH3ciJ+zb+Xb6Vz6zTG9enQgJGJfCaS4l7bOSSv8fxToK+7jwH+CEyt7Y3c/XF3z3L3rMzMzPpF2sS4O7c+t4CL/vgR767cVmf7lQX7WFdYzEXqSCeNI2p5Dc0rtx//YD1z1u/kkXfWsLJgb53tSyuqeH/Vds4d3pXkJJ2Sl8YRSXHPBXqHPe8F5JEWiMYAABXiSURBVIc3cPe97r4/9HgGkGpmnaMWZRP0rwW5fLi2iPatUvnei4tYu23fEdu/sSSf5CRjok7bSeNQXh+FzTtK+NN7OZx9XCbtWqVy92tLCQRq7hMd6uN1RRSXV+kWOGlUkRT3+cBgM+tvZmnAVcD08AZm1s1CvUTMbHzofXdEO9imYvveUh58YwXj+3Xkje+eTsvUZG55NpvdJeW1tg+eki/g1IGd6NS6RSNHK82U8rqe3J37py8jJcn4v8tHc/cFw/h0827+mb3liK+buWwbbVqkcOrATo0UqUgExd3dK4HbgZnASuAld19uZrea2a2hZlcAy8xsMfAH4Cp3P/LubIJyd+6dtoyyygAPf2UUPdu34q/XnUDB7lJu+8enVFQFPveaJbl72LyzhIt1Sl4aifK6/t5esY33Vhfyg3OH0K1dSy4f15OT+nfk4bdWUbS/rNbXVFYFeGflNs4e2oUWKcmNHLE0ZxHd5+7uM9x9iLsPdPeHQssec/fHQo//5O4j3H2Mu5/s7h83ZNDxbMbSrcxcvo0fnDuEAZmtATihbwceumwks3N28NCbKz/3mjeW5JOabBpvWhqV8jpyJeWV/HT6coZ2a8MNp/YDwMx46LKRlJRX8osZn89rgOxNu9hZXK7clkanEeqiaFdxOfdPX8aonu245Qv9D1l3ZVZvbvlCf6Z8vJEX5m0+uDwQcN5cUsAZgzNpl57a2CGLSAT+8G4O+XtK+fmlI0lN/uzf5qAubfjWGQN59dM8Pl5X9LnXzVy+lbSUJM46LrE7GUr8UXGPop+9sYLdJRX88iujSUn+/KadPHEoZwzJ5N6py5i7Pnjp8tPNu8jfU8pFY3Rvu0g8WrNtH3/7cD1fzepFVr+On1t/+xcH0adjOvdMXUZZZdXB5e7O28u3cfqgzmS0qHO8MJGoUnGPkvdWbee1hXl8+6yBDO9R+/CSKclJ/PHq4+nTMZ3/ef5TcneV8MaSAlqkJPGlYRpvWiTeuDv3TF1G65YpTJ44rNY2LVOT+dklI1hfWMwTs9YfXL4sby95uw9wvu6AkRhQcY+CfaUV/OS1pQzu0prbvjjoiG3btUrliRuyqKgKcMsz2by5tICzj+tCm5Y6JS8Sb15bmMe8DTu5c8JQOmakHbbdWcd14YJR3fjjf3PYvKMECJ6STzK04y4xoeIeBQ+/tYpte0v51RWjI+oROzCzNX+6Zhxrtu2jcF+ZTsmLxKE9JRX8YsZKxvZuz9eyetfZ/r6LRpCSZNw7bRnuzszlWxnfv+MRdwpEGoqK+zH6ZN0Onp+7mW+c1p/j6zG05JlDMvnZJSMZ27s9XxzapQEjFJGj8Zu3V7OzuJyfXzqSpAhGluvWriU/PO84PlhTyKPv5bB2+371kpeYUS+PY3CgvIrJry6hT8d0fnjecfV+/ddP7svXT+7bAJGJyLFYkrub5+Zu4oZT+jGyZ7uIX3f9KX155dNcfvP2GgAVd4kZHbkfg//3nzVs2lHCw18ZRas0DVAhkggqqwLcM3UZnVu34I7zhtTrtSnJSTx02SjMYHSvdvRo36qBohQ5Mh25H6Xl+Xt48qMNXHVib04d2KyH2xZJKE/N3sCS3D388erjaXsUHV3H9m7PI18dQ8/26Q0QnUhkVNyPQlXAuevVpXRIT+Wuw9weIyJNz4aiYn779hrOHd6Vi0YffUfXy47vFcWoROpPp+WPwt8/2ciS3D3ce9FwjSonkiACAefOfy0hLSWJn186ktCcOSJNkop7PRXsOcCvZ67mjCGZfHmMJnoRSRTPz93EvI07ufei4XRt2zLW4YgcExX3erp/2nKq3HlIe/YiCSN3VwkPv7WK0wd35soTdEpdmr6IiruZTTCz1WaWY2aTj9DuRDOrMrMrohdi/Ji5fCtvr9jG984ZQu+O6iwjTZvyOsg92IfGgV9cNko77ZIQ6izuZpYMPApMBIYDV5vZ8MO0+yXB+aETzv6ySu6fFpzy8ZbT+9f9ApE4prz+zL8W5PLh2iImTxyqnXZJGJEcuY8Hctx9vbuXAy8Cl9TS7jvAK8D2KMYXN34zczXb9pXyf5ePOmTKR5EmSnkNbN9byoNvrGB8v458/SQNKCWJI5Iq1RPYEvY8N7TsIDPrCVwGPHakNzKzSWaWbWbZhYWF9Y01ZhZv2c0zn2zkupP71muIWZE4FrW8DrVtcrldPeNbWWWAh78yKqIhZkWaikiKe21/8V7j+e+AO929qpa2n73I/XF3z3L3rMzMzEhjjKnKqgB3vbqULm1a8KPz6z/ErEicilpeQ9PM7TeXFvD2im3cce4QBmS2jnU4IlEVySA2uUD4lEi9gPwabbKAF0MdUToDF5hZpbtPjUqUMfT07I2sKNjLX64dd1SjVYnEqWad1zuLy7l/2nLG9GrHzV9QHxpJPJEU9/nAYDPrD+QBVwHXhDdw94PZYWZTgDcS4R/Alp0lPPLOGr40rAsTRmoCCEkozTav3Z0Hpi9nb2kFv7riZFLUh0YSUJ3F3d0rzex2gr1lk4Gn3H25md0aWl/n9bimaMvOEr75bDZm8NNLdE+7JJbmmtfuzsP/XsX0xfncce4QjuvWJtYhiTSIiMaWd/cZwIway2pNfne/8djDiq0563fw7ec/pbIqwOPXZdFTMztJAmpuee3uPPTmSv720QauO7kvt589KNYhiTQYTRxTw/NzN3H/tOX07ZTO3244kf6dM2IdkogcI3fnZ2+s4OnZG7nx1H7cf/FwnY2ThKbiHlJRFeBnr6/g73M2cfZxmfz+KKd7FJH4Un2N/ZlPNvGN0/pz70XDVNgl4am4E+w5++3nFzBn/U6+deYA/vf8oSTrnleRJi8QcO6bvozn5mxm0hkDuGviUBV2aRaafXFfvXUftzw7n217y/h/XxujeZhFEkQg4Nw9dSkvzNvC/5w1kP89/zgVdmk2mnVx/++qbXznHwvJaJHCS986hbG928c6JBGJgkDAmfzqEl7KzuX2swfxw/OGqLBLs9Jsi/uMpQV894WFDOvelieuz6JbO83fLJIIKqsC3PnKUl75NJfvnTOY739psAq7NDvNsrhPW5THHS8tZlyf9jx144m0Ucc5kYRQXFbJ7f/4lPdWF3LHuUP47jmDYx2SSEw0u+L+yoJcfvyvxYzv35EnbziRjBbNbhOIJKTt+0q5eUo2y/P38NBlI7lWs7xJM9asKts/529m8qtLOW1gZ564PotWacmxDklEoiBn+z5ueGo+O4vL+dsNWXxxaNdYhyQSU82muD83ZxP3TF3GmUMy+et1J9AyVYVdJBHMXb+DSX9fQGpyEv/81smM7qWOsSLNorhPmb2BB15fwTlDu/Dnr4+jRYoKu0gimL44nx+9tJjeHVsx5abx9O6YHuuQROJCwhf3v324np+/uZLzR3Tlj1ePIy1FM0CJNHXuzl9nrefht1Yxvn9Hnrgui3bp6hgrUi2iSmdmE8xstZnlmNnkWtZfYmZLzGyRmWWb2ReiH2r9/fn9HH7+5kouHNWdP12jwi4SrqnmdSDg3DdtOQ+/tYqLx/Tg7zePV2EXqaHOI3czSwYeBc4FcoH5Zjbd3VeENXsXmO7ubmajgZeAoQ0RcKT+8O5aHnlnDZeM7cFvrxyjOZtFwjTVvAZ4aMZK/j5nE986YwB3ThhKkoaKFvmcSCreeCDH3de7eznwInBJeAN33+/uHnqaATgx4u488s4aHnlnDZeP68kjXx2rwi7yeU0qr6s9+dEGnvxoAzed1o/JE1XYRQ4nkqrXE9gS9jw3tOwQZnaZma0C3gS+EZ3w6sfd+fXM1fzh3bV8NasXv75ijCaAEaldk8nrajOWFvDzN1cwYUQ37rlQU7aKHEkkxb22DPrcHry7v+buQ4FLgQdrfSOzSaFrd9mFhYX1i7QO7s7/vbWKP7+/jmtO6sPDl49WYRc5vKjlNTRsbgPM37iT7/9zEeP6dOB3V41VbovUIZLingv0DnveC8g/XGN3nwUMNLPOtax73N2z3D0rMzOz3sEe4TP52RsreHzWeq4/pS8PXTpSp+tEjixqeR1a3yC5DbCucD/ffDabXu1b8cT1WRqjQiQCkRT3+cBgM+tvZmnAVcD08AZmNshC58jMbByQBuyIdrC1cXfun76cp2dv5KbT+vHTL4/Q6TqRusV1Xlfbvq+UG56aR0qSMeWm8XTMSGvMjxdpsursLe/ulWZ2OzATSAaecvflZnZraP1jwFeA682sAjgAfC2sI06DCQSce6Yt4x9zNzPpjAHcNXGoCrtIBOI5r6sVl1Vy85Rsduwv58VJJ9OnkwaoEYmUNWKuHiIrK8uzs7OP+vXuzt1Tg4X922cN5MfnH6fCLs2amS1w96xYx3GsuQ3BaVu/+Ww2H6wp5InrszhnmMaKl+braHK7yY5Q95cP1vGPuZv5HxV2kYTi7tw7bTnvrS7koctGqrCLHIUmeQP4m0sK+NW/V/PlMT34XxV2kYTh7vxixkpemLeZ284eqGlbRY5SkztyX7h5F3e8tIgT+nbgV1eMVmEXSRDuzoNvrOSp2Ru44ZS+/Oi842IdkkiT1aSK+5adJXzz2Wy6tm3J45q2VSRhuDs/fX0FUz4O3vVy30UapEbkWDSZ4r63tIKbn5lPWWWAFyedSKfWLWIdkohEQfXtrM9+solbvtCfuy8cpsIucoyaRHGvrApw2/Ofsr6wmGe/MZ5BXVrHOiQRiYJAwLl32jKe1+2sIlEV98W9eq/+w7VF/PIrozh1UK0DZIlIExMIOHdPXcoL87Zw65kDuXOCOseKREvcF/cnP9rA83M3c+uZA/naiX1iHY6IREEg4Nz16lL+mb2F284eyI/OU2EXiaa4Lu7vrNjGQzNWMnFkN/73fPWcFUkEVQFn8itLeHlBLt/54iDuOHeICrtIlMVtcS+tqOInry1ldM92PPLVsZoIRiRBzFhawMsLcvneOYP5/pcGq7CLNIC4Le4tU5N59hvj6dQ6jVZpuuVNJFFcNLo7bVulcuaQ6M4eJyKfidviDjCse9tYhyAiUWZmKuwiDaxJDj8rIiIihxdRcTezCWa22sxyzGxyLeuvNbMloa+PzWxM9EMVkWhSXoskrjqLu5klA48CE4HhwNVmNrxGsw3Ame4+GngQeDzagYpI9CivRRJbJEfu44Ecd1/v7uXAi8Al4Q3c/WN33xV6OgfoFd0wRSTKlNciCSyS4t4T2BL2PDe07HBuBt6qbYWZTTKzbDPLLiwsjDxKEYm2qOU1KLdF4k0kxb22m1C91oZmZxP8J3Bnbevd/XF3z3L3rMxM9ZYViaGo5TUot0XiTSS3wuUCvcOe9wLyazYys9HA34CJ7r6jrjddsGBBkZltqqNZZ6AoghhjJd7jg/iPUfEdu+oY+9bjNQ2S16DcbiTxHh/Ef4xNKb765DYA5l7rzvpnDcxSgDXAOUAeMB+4xt2Xh7XpA/wXuN7dP65vEEf47Gx3z4rW+0VbvMcH8R+j4jt2RxNjLPM69N5xvV0V37GL9xgTPb46j9zdvdLMbgdmAsnAU+6+3MxuDa1/DLgP6AT8OTSUZGU8bzSR5k55LZLYIhqhzt1nADNqLHss7PEtwC3RDU1EGpLyWiRxxfsIdfF+X228xwfxH6PiO3ZNIcaa4j1mxXfs4j3GhI6vzmvuIiIi0rTE+5G7iIiI1JOKu4iISIKJ2+Je16QWsWBmG81sqZktMrPs0LKOZvaOma0Nfe/QiPE8ZWbbzWxZ2LLDxmNmd4W252ozOz+GMT5gZnmh7bjIzC6IRYxm1tvM3jOzlWa23My+F1oeN9vwCDHGxTasL+V1xDHFdW7Hc16HPi+uc7tR8trd4+6L4K0564ABQBqwGBgeB3FtBDrXWPYrYHLo8WTgl40YzxnAOGBZXfEQnBxkMdAC6B/avskxivEB4Ee1tG3UGIHuwLjQ4zYE7/seHk/b8AgxxsU2rOfPoryOPKa4zu14zuvQZ8Z1bjdGXsfrkXudk1rEkUuAZ0KPnwEubawPdvdZwM4I47kEeNHdy9x9A5BDcDvHIsbDadQY3b3A3T8NPd4HrCQ4vnrcbMMjxHg4Mfk9R0h5HaF4z+14zmuI/9xujLyO1+Je30ktGosDb5vZAjObFFrW1d0LIPgLA7rELLojxxNv2/R2C84T/lTYqbGYxWhm/YDjgbnE6TasESPE2TaMQLzG1hTyGuL077KGuPubjPfcbqi8jtfiHvGkFo3sNHcfR3AO7NvM7IxYB1QP8bRN/wIMBMYCBcBvQ8tjEqOZtQZeAb7v7nuP1LSWZY2yDWuJMa62YYTiNbamnNcQP9s17v4m4z23GzKv47W4RzSpRWNz9/zQ9+3AawRPi2wzs+4Aoe/bYxchHCGeuNmm7r7N3avcPQA8wWenlxo9RjNLJZhcz7v7q6HFcbUNa4sxnrZhPcRlbE0kryHO/i5rire/yXjP7YbO63gt7vOBwWbW38zSgKuA6bEMyMwyzKxN9WPgPGBZKK4bQs1uAKbFJsKDDhfPdOAqM2thZv2BwcC8GMRXnVTVLiO4HaGRYzQzA54EVrr7I2Gr4mYbHi7GeNmG9aS8PjZx83dZm3j6m4z33G6UvG6o3oBR6E14AcEehOuAu+MgngEEeysuBpZXx0RwYo13gbWh7x0bMaYXCJ66qSC4Z3fzkeIB7g5tz9UEp/CMVYx/B5YCS0J/tN1jESPwBYKntpYAi0JfF8TTNjxCjHGxDY/i51FeRxZXXOd2POd16PPiOrcbI681/KyIiEiCidfT8iIiInKUVNxFREQSjIq7iIhIglFxFxERSTAq7iIiIglGxb2ZMbO7Q7MQLQnNOnSSmX3fzNJjHZuIHD3ltoTTrXDNiJmdAjwCnOXuZWbWmeDsXB8DWe5eFNMAReSoKLelJh25Ny/dgSJ3LwMIJfwVQA/gPTN7D8DMzjOzT8zsUzN7OTT+cfW81780s3mhr0Gh5Vea2TIzW2xms2Lzo4k0a8ptOYSO3JuRUCJ/BKQD/wH+6e4fmNlGQnv3oT3+VwmOgFRsZncCLdz9Z6F2T7j7Q2Z2PfBVd7/IzJYCE9w9z8zau/vumPyAIs2Ucltq0pF7M+Lu+4ETgElAIfBPM7uxRrOTgeHAbDNbRHD85b5h618I+35K6PFsYIqZfRNIbpjoReRwlNtSU0qsA5DG5e5VwPvA+6G98htqNDHgHXe/+nBvUfOxu99qZicBFwKLzGysu++IbuQiciTKbQmnI/dmxMyOM7PBYYvGApuAfUCb0LI5wGlh19zSzWxI2Gu+Fvb9k1Cbge4+193vA4o4dGpCEWlgym2pSUfuzUtr4I9m1h6oBHIInsa7GnjLzArc/ezQ6bwXzKxF6HX3EJzJC6CFmc0luGNYfQTw69A/FiM409LiRvlpRKSaclsOoQ51ErHwzjmxjkVEoke5nXh0Wl5ERCTB6MhdREQkwejIXUREJMGouIuIiCQYFXcREZEEo+IuIiKSYFTcRUREEsz/B7lC2plhIeJtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test objective as a function of steps.\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "ax[0].plot(np.arange(1, num_steps + 1, 10), train_objectives)\n",
    "ax[0].set_title('Train PR-AUC')\n",
    "ax[0].set_xlabel('Steps')\n",
    "ax[1].plot(np.arange(1, num_steps + 1, 10), test_objectives)\n",
    "ax[1].set_title('Test PR-AUC')\n",
    "ax[1].set_xlabel('Steps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0] [0. 0. 0. ... 0. 0. 0.]\n",
      "Precision = [0.78687295 0.        ]\n",
      "Recall= [1. 0.]\n",
      "F1 Score = [0.88072624 0.        ]\n",
      "Accuracy0.7868729488982653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(pred_labels, y_test)\n",
    "\n",
    "precisions, recall, f1_score, true_sum = metrics.precision_recall_fscore_support(y_test, pred_labels)\n",
    "\n",
    "print(\"Precision =\", precisions)\n",
    "print(\"Recall=\", recall)\n",
    "print(\"F1 Score =\", f1_score)\n",
    "accuracy_score = metrics.accuracy_score(y_test, pred_labels)\n",
    "print('Accuracy' + str(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1b) ROC-AUC Training with Plain TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create context with labels and predictions.\n",
    "context = tfco.rate_context(logits_fn, labels_fn)\n",
    "\n",
    "# Create optimization problem with PR-AUC as the objective. The library\n",
    "# expects a minimization objective, so we negate the PR-AUC. \n",
    "\n",
    "# We use the roc_auc rate helper which uses a Riemann approximation to the area \n",
    "# under the precision-recall curve (recall on the horizontal axis, precision on \n",
    "# the vertical axis). We would need to specify the the number of bins \n",
    "# (\"rectangles\") to use for the Riemann approximation. We also can optionally\n",
    "# specify the surrogate to be used to approximate the ROC-AUC\n",
    "roc_auc_rate = tfco.roc_auc(\n",
    "    context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "problem = tfco.RateMinimizationProblem(-roc_auc_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lagrangian loss for `problem`. What we get back is a loss function, a \n",
    "# a nullary function that returns a list of update_ops that need to be run \n",
    "# before every gradient update, and the Lagrange multiplier variables internally\n",
    "# maintained by the loss function. The argument `dual_scale` is a \n",
    "# hyper-parameter that specifies the relative importance placed on updates on \n",
    "# the Lagrange multipliers.\n",
    "loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "    problem, dual_scale=1.0)\n",
    "\n",
    "# Set up optimizer and the list of variables to optimize.\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "var_list = (model.trainable_weights + problem.trainable_variables + \n",
    "            [multipliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(model, features, labels):\n",
    "    # Returns the ROC-AUC for given model, features and binary labels.\n",
    "    scores = model.predict(features)\n",
    "    return metrics.roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAD0CAYAAAB3nTSwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcdX3/8dd7d7NZcg8khEuABIxiflpSTINoHypVMMHyQ61aoC2I2pRfwUtbL1H7s/qr+vBSfdgW2hR/5YdUBC+AxhoEa2upFCVBE5IA0RDAxIRkwyXJTrK7md3P749zJhmG2d25JTNz8n4+HvPYmXOZ+cwkn/M553u+53wVEZiZmVm2dDQ7ADMzM2s8F3gzM7MMcoE3MzPLIBd4MzOzDHKBNzMzyyAXeDMzswxygc8QSXdKuqLZcZiZWfO5wDeZpL6ix7Ck/UWv/6Ca94qIJRHxlRrjeLzos5+UdKOkSSXLvELSv0vaK2m3pO9Kml+yzBRJX5L0q/S9NqWvZ4zx+TdKyks6qcz0T5ZMmyMpJHUVTbtM0ur0M7enOzu/XctvYdZIjczx9P1+JOldo8wv5EfhMx6XtKzMcm+XtE7SvjTn/1HStJJlXijpm5J2pTn/oKQ/l9Q5yudL0mZJD5WZ97ik15WJ48dFr7slfVzSLyXl0nVukDRn9F/GSrnAN1lETCo8gF8BFxVNu7mwXHExO4wuSuNYAPwm8OGizz8XuBv4DnASMBdYC9wr6fR0mW7gh8D/ABYDU4BXAE8Bi0b6UEkTgd8DdgO1bPD+HPgS8GlgFnAq8A/AxdW+l1mjVZrjh8G09DPfAvxvSecXZkj6C+CzwAeAqcDLgdOAH6R5jKQzgJ8CW4CXRsRU4K3AQmDyKJ/7KuB44HRJv1VD3N8C/idwWRrbWcADwGtreK+jW0T40SIP4HHgdenz1wBbgQ8BTwL/AkwH/hXoBZ5Jn88uWv9HwLvS528Hfgz8TbrsY8CSSj47ff054HtFr/8L+Icy690J3JQ+fxewA5hU5fe+nGQj8l5gfcm8G4FPlkybAwTQRbIB6APe2ux/Pz/8GOtRkuMdwDLgUZKd4G8Ax6bzeoCvptOfBVaR7Lx+ChgC+tP/99eW+YyD+VE07X7gA+nzKem6bytZbxKwE3hH+vqrxduAKr7jDcDNwO2l8ZVuZ9Jpbwd+nD5/HbAfOKXZ/1ZZePgIvrWdABxLsme9lGSD8P/S16eSJMK1o6x/DrARmEFSsP9Zksb6UEmzgSXApvT1BJIj8W+WWfwbQOHI4HXA9yOib6zPKHEFcAtwK3CmpLOrWPdcko3hHVV+plmzvQd4I/BqklaxZ4Dr0nlXkOy8ngIcB1wF7I+Ij5LsbF8TSQvANWN9iKSXAy8hzWeSXO4hKcAHpXl7J8/N529V84XSbcVbSAr8zcAlhRaBCr0OuD8itlTzuVaeC3xrGwb+KiIGImJ/RDwVEbdFxL6I2EuyN//qUdZ/IiK+HBFDwFeAE0mOAkbybUl7SY6mdwJ/lU4/luT/yvYy62wn2YGAZENUbpkRSToVOA/4WkTsIGnir6aj4HHArojIV/O5Zi3gT4CPRsTWiBgAPg68JT0dd4Dk//YLImIoIh6IiD1Vvv8uSfuB+0hOWX07nT6DkXOmrnwG3gwMkJzO+1eSVrY3VLF+LZ9pI3CBb229EdFfeCFpgqR/kvSEpD3APcC0UTq8PFl4EhH70qeTRlgW4I0RMZnk9MCZHEr0Z0h2Nk4ss86JwK70+VMjLFOI/w+KOv7cmU7+I+DhiFiTvr4ZuEzSuPR1HhhX8lbj0niG08+ccYT6KJg10mnAHZKelfQs8DBJ8/ssklNydwG3Stom6XNFOVGpGST5/n6SnC6sv4uRc6aafF5elM8fSSdfAXwjIvLpTsvtPHeHfaR8PlDJZ1p1XOBbW+lQf38BvAg4JyKmkHRmARiz2b2qD434T5Jz33+Tvs6RHAW8tczibyM56gb4N+D1aae5cu97cxzqXLQknXw5SWecJyU9CXyRZMNUmP8rknOKxeYCWyJiOI2rn6Sp06ydbCHpFzOt6NETEb+OiAMR8YmImE/SpP67JLkCz98ujCg9+v8CSY78aTr5PpKj7DcXL5vm7RKem8+/N8p7X1WUz59OT+39DvCHRfn8FuDCoqtoRsrnJ4o+c1H6XlYnF/j2MpnkvPuzko7lUBP64fAl4HxJC9LXy4ArJL1H0mRJ09PL184FPpEu8y8kG63bJJ0pqUPScZI+IunC0g9Ie+afQdLDfkH6eAnwNQ7t9d8GvEHSBZI608vo/pLkfD0RsRv4GHCdpDemrRzjJC2R9LmG/ypmjbMc+JSk0wAkzZR0cfr8PEkvTVvn9pAc4Q6l6+0ATq/ysz4DfFBST5oznwD+XtLiNF/mkPSx2UqSx5BsX14h6fOSTkjjeoGkr5ZeTpf6I+AXJAchhXx+Yfqel6bLfB14X7p9kKSFwDs4lM//BvyApGXjZZK60u3NVZLeUeV3tmb38vPj0IMyvehL5p9E0lO+jySR/oSi3rKU6UVfsn6QnNMb9bOLpv0jcFvR698u+vw9wPeAl5SsM5Vk52BLutyjJEflx5X5zOXF7180fRHJEUahR/FFJJfJ7CbZ0/88cEzJOn8ArAZyJKcmvge8otn/pn74Ufzg+b3o/5ykI+zeNFc+nc67NJ2eIynof1eU5+em+f8M8HdlPmMOz+9FL2AD8O6iae8E1pMcNOwA/gmYXvJeLyIp/E+l+bcWeB/QWeZzHyl+/6LpHwRWF33nZcAv023IQ8A7S5bvJtkB2ZR+/yeA/wuc2ux/v3Z7KP1BzczMLEPcRG9mZpZBLvBmZmYZ5AJvZmaWQS7wZmZmGdSSNweZMWNGzJkzp9lhmLWVBx54YFdEzGx2HCNxXpvVptbcbskCP2fOHFavXt3sMMzaiqQnxl6qeZzXZrWpNbfdRG9mZpZBLvBmZmYZ5AJvZmaWQS7wZmZmGTRmgZd0g6SdktaPMF+S/k7SJkkPSjq7aN5iSRvTecsaGbiZ1ce5bZZtlfSivxG4FrhphPlLgHnp4xySAUrOSUdBug44n2Q0oVWSVkTEQ/UGnSWlYwGUDg3gkQIMkpFCOjoaOiowOLdbWjJgiLcBWdfZ+Lw+aMwCHxH3pEMJjuRi4KZIKtVPJE2TdCLJiEabImIzgKRb02VbciOwe/8BNvf28Whvji1P72P3/gP0DeTZ23+Avf359JE8H4pg1uQeZk3t4YQp4zlhSg8nTD2GE6aOZ9aUHjokntzdz7bd+9n+bD/bd/ezfff+g3/7Dww3++tam/nCW8/i917W2CGyj4bcHh4OnsoNsmNPP0/u7ufp3CB7+g+we/8B9uxP//bnD74+pruTGZPGM2NSd/p3PDMmJ6+Pmzievf0H2Ll3gJ17+pO/hceefp7KDT5nh73czvpwBEPDSeEufT4cQZRZz7Kru6uDX3xyyWF7/0ZcB38yydCgBVvTaeWmnzPSm0haCiwFOPXUUxsQ1sh+svkpHtz6LJt7c8ljVx+7+gaLYoFJ3V1M7ulics84Jvd0MWNSN3NnTGRSTxcdgh17Btixp59Htu+ht29gxKTs7BCzJo/nhKk9zD9pCq8983gmjn/uz66SHTihUefb0Wf+SVOa8bF15/aRzOtNO/v46k+e4Mnd/ezY28+O3UkRzg8/PzklmNIzjinHdDH1mHFM6RnHGTMnsf/AEDv29LNh226e6hssu25BV4eYOXk8x08ez+zpE1hwyrTnHY2V5m6nhCQ6O0SHoEOiI30uhJS01qBkK6Ci6ZY9h/PoHRpT4MtFGKNMLysirgeuB1i4cOFh24f91gNbef831wJw7MRuTp8xkdeeOYvTZ07k9JmTOH3mRE49dgLjOivvf3hgaJjevQM8uSfZqAwHnDith5OmHsOMSd10VfFeZi2k7tw+Unm9bzDPO25cxY49/Zx67ARmTenh3DNmMGtKsnN9/OQeTpjaw3ETu5k6YRyTurvGPOUxPBzs3n+A3r4Bdu0d4Ol9g0wa38WsKT0cP3k80yd0H47TJmYN04gCvxU4pej1bGAb0D3C9KbZ3NvHx76znnPmHsvyP3wZ0yd2N+R9x3V2cNK0Yzhp2jENeT+zFtE2uf2ZOx9hyzP7uPWPX845px/XkPfs6BDTJ3YzfWI3L5w1uSHvaXYkNeLQcgVwedrj9uXA7ojYDqwC5kmaK6kbuCRdtikG8kO8+5af093VwZcuWdCw4m6WYW2R2/du2sVN9z3Bla+Y27DibpYFYx7BS7oFeA0wQ9JW4K+AcQARsRxYCVwIbAL2AVem8/KSrgHuAjqBGyJiw2H4DhX57J0b2bBtD1++fCEnTvWRtlkWcntv/wE++K0HOX3GRD64+EXNCMGsZVXSi/7SMeYHcPUI81aSbCSa6t8f2cEN9z7GFeeexvnzZzU7HLOWkIXc/tT3Hmb77v1863+9gp5xnc0Ox6ylZL731449/bz/mw9y5gmT+fCFL252OGbWID/auJNbV23hj191OmefOr3Z4Zi1nEwX+KHh4M++voZ9g3muvew3vYdvlhG79x9g2W3rmHf8JP7sdS9sdjhmLaklx4NvlH+651H++9Gn+MybX8oLjncvWLOs+MR3N9DbN8D1l7/MO+5mI8jsEfzPfvUMX7j7F7zhN07k93/rlLFXMLO28IOHdnD7z37Nn77mDH5j9rRmh2PWsjJZ4Pf0H+A9t/ycE6b08Ok3vRT5NlBmmfBMbpAP376OF584hXf/zrxmh2PW0jLZRP+xb69n++5+vvEn5zL1mHHNDsfMGuRjKzawe/8gN71jEd1dmTw+MWuYzGVIRLBi7TYuW3QqLzvNPWvNsuK/H93Fd9du4z2/M69Z9+Y3ayuZK/D7BocYDjh5um9mY5Ylj+7sA+D3F7lPjVklMlfgcwN5gOeN2GZm7a1vYAiASc5ts4pkrsD3pQV+0nhfOmOWJbmBPB2CY3xZnFlFMlfg9w0me/kTu72Xb5YlfQN5JnZ3+aoYswplrsAfOoJ3gTfLktxA3qfezKqQuQLvc/Bm2ZQbzDPRp97MKpa5At/nAm+WSX0DQ26ZM6tC5gp8zj1tzTLJTfRm1clggS8cwbspzyxLXODNqpO5Al9oop/gXvRmmdI3kHfLnFkVKirwkhZL2ihpk6RlZeZPl3SHpAcl3S/pJUXzHpe0TtIaSasbGXw5uYE8x4zrpLPDl9KYjaad8hoKR/BumTOr1Ji7w5I6geuA84GtwCpJKyLioaLFPgKsiYg3STozXf61RfPPi4hdDYx7RElPW+/lm42m3fIakv41zm2zylVyBL8I2BQRmyNiELgVuLhkmfnADwEi4hFgjqRZDY20QklPW+/lm42hrfJ6MD/M4NAwk3zqzaxilRT4k4EtRa+3ptOKrQXeDCBpEXAaMDudF8Ddkh6QtHSkD5G0VNJqSat7e3srjf953BHHrCJtl9fgy1/NqlFJgS93MjtKXn8GmC5pDfBu4OdAPp33yog4G1gCXC3pVeU+JCKuj4iFEbFw5syZlUVfRp8LvFkl2i6vwZe/mlWjkmzZChSPzzgb2Fa8QETsAa4EUHKj6MfSBxGxLf27U9IdJE2D99Qd+QhyA3lmTek5XG9vlhXtldeDPoI3q1YlR/CrgHmS5krqBi4BVhQvIGlaOg/gXcA9EbFH0kRJk9NlJgIXAOsbF/7zuYnerCJtl9fg+1uYVWPMShgReUnXAHcBncANEbFB0lXp/OXAi4GbJA0BDwHvTFefBdyRjv7UBXwtIr7f+K9xiDvZmY2tHfMa3ERvVo2KsiUiVgIrS6YtL3p+HzCvzHqbgbPqjLEquXRISTMbXbvlNbiJ3qwambqT3dBwsP+Ar5U1yxp3sjOrXqYKfKEjjjcCZtniI3iz6mWrwHsjYJZJ7mRnVr2MFnhvBMyypG9giO7ODsZ3ObfNKpWpAu+etmbZ5IFmzKqXqQLvJnqzbPL9Lcyql6kC7562ZtnkseDNqpepAu8jeLNs8jDQZtXLaIH3uTqzLOnzWPBmVctUgXcnO7Nsyg3kfQtqsyplqsDnBvJ0CI4Z5w2BWZb4FtRm1ctUge9LNwLpIBhmlhF9/T4Hb1atTBV4X0pjlj0RQW7QvejNqpWtAj/om2GYZc3+A0MMh6+OMatWpgp8Mha8NwJmWXLo/hbeeTerRqYKvJvozbInl14d49w2q44LvJm1NN/Ayqw2mSrwvp2lWeUkLZa0UdImScvKzJ8u6Q5JD0q6X9JLKl23kXwLarPaVFTg22VD4BGnzCojqRO4DlgCzAculTS/ZLGPAGsi4jeAy4G/rWLdhvERvFltxizwbbUhGPTtLM0qtAjYFBGbI2IQuBW4uGSZ+cAPASLiEWCOpFkVrtsw7mRnVptKjuDbYkNwYGiYwfwwk3y3K7NKnAxsKXq9NZ1WbC3wZgBJi4DTgNkVrku63lJJqyWt7u3trSlQd7Izq00lBb4tNgRuxjOrSrnbPUbJ688A0yWtAd4N/BzIV7huMjHi+ohYGBELZ86cWVOgzm2z2lSSMZVuCP423RCso8YNAXA9wMKFC8suMxp3xDGrylbglKLXs4FtxQtExB7gSgAl939+LH1MGGvdRirktu9Fb1adSjKmLTYEbsYzq8oqYJ6kucCvgUuAy4oXkDQN2JeeXnsXcE9E7JE05rqNlBvIc8y4Tjo7PMaEWTUqqYZtsSHo81jwZhWLiLyka4C7gE7ghojYIOmqdP5y4MXATZKGgIeAd4627uGKNbkFtXfczao1Zta0y4Yg5yZ6s6pExEpgZcm05UXP7wPmVbru4ZLcgto77mbVqqgatsOGwB1xzLLJd6g0q01m7mTnTnZm2dTnAm9Wk8wUeB/Bm2VTzregNqtJdgr8YKEXvc/VmWWJm+jNapOZAt83kGdcpxjf5QJvliXuZGdWm8wUeO/lm2VTbiDvm9yY1SAzBb7PGwGzzBkaDvYf8CBSZrXITIF3Rxyz7MkN+uoYs1plqMAPuYOdWcb46hiz2mWmwPtaWbPsyfkW1GY1y0yBd0ccs+zpSweRchO9WfWyVeC9ETDLFI8xYVa7zBT4voG8r5U1y5g+n4M3q1kmCnxEkBv0pTRmWeMjeLPaZaLAD+SHGRoOF3izjHEverPaZaLAeyQ5s2xyJzuz2mWiwHsv3yybcgN5OgQ94zKxqTI7ojKRNYeO4N3JzqxSkhZL2ihpk6RlZeZPlfRdSWslbZB0ZdG8xyWtk7RG0urDFWPh/haSDtdHmGVWRQW+1TcEuYHCULE+gjerhKRO4DpgCTAfuFTS/JLFrgYeioizgNcAX5DUXTT/vIhYEBELD1ecvgW1We3GzJyiDcH5wFZglaQVEfFQ0WKFDcFFkmYCGyXdHBGD6fzzImJXo4MvcBO9WdUWAZsiYjOApFuBi4HivA5gspLD50nA00D+SAbpO1Sa1a6SI/iDG4K0YBc2BMWauiFwJzuzqp0MbCl6vTWdVuxa4MXANmAd8N6IGE7nBXC3pAckLR3pQyQtlbRa0ure3t6qg3SBN6tdJQX+iGwI6uEjeLOqlTupHSWvXw+sAU4CFgDXSpqSzntlRJxN0sR/taRXlfuQiLg+IhZGxMKZM2dWHWTON7Ayq1klBf6IbAjq2dM/eATve9GbVWorcErR69kkO+jFrgRuj8Qm4DHgTICI2Jb+3QncQdLS13C5gSGPMWFWo0oK/BHZENSzp3+ok5339M0qtAqYJ2lu2nHuEmBFyTK/Al4LIGkW8CJgs6SJkian0ycCFwDrD0eQfe5kZ1azSgp8y28IcoN5xnd10NWZiav+zA67iMgD1wB3AQ8D34iIDZKuknRVuthfA6+QtA74IfChtLPsLODHktYC9wPfi4jvH444c4M+B29WqzEzJyLykgobgk7ghsKGIJ2/nGRDcGO6IRDphkDS6cAd6TWsXcDXDseGwHv5ZtWLiJXAypJpy4uebyPZKS9dbzNw1mEPEI8SaVaPijKn1TcE3giYZc9AfogDQ+FOdmY1ykSbtgu8Wfb4BlZm9clIgR/yXr5ZxvjyV7P6ZKPAuyOOWeb4BlZm9clEgffdrsyyx0fwZvXJRIHPDeR9kxuzjPEokWb1yUiBH/JevlnGuJOdWX3avsBHBLlB36/aLGsONtG7dc6sJm1f4PcNDhHhvXyzrHEnO7P6tH2Bd0ccs2xybpvVp+0LvPfyzbKpbzBPd2cH3V1tv5kya4q2zxx3xDHLpuQOle5bY1arti/wfQeb8bwhMMsSXx1jVp+2L/A5N9GbZZJHiTSrT/sX+EF3xDHLIg8iZVafti/w7mRnlk0u8Gb1afsC70tpzLIpaaJ33xqzWrV9ge9Le9FPGOcNgVk1JC2WtFHSJknLysyfKum7ktZK2iDpykrXbYTcwJDvYmdWh7Yv8LmBPBO7O+noULNDMWsbkjqB64AlwHzgUknzSxa7GngoIs4CXgN8QVJ3hevWzU30ZvWpqMC38p6+NwJmNVkEbIqIzRExCNwKXFyyTACTJQmYBDwN5Ctcty6HxphwbpvVaswC3+p7+r6UxqwmJwNbil5vTacVuxZ4MbANWAe8NyKGK1wXAElLJa2WtLq3t7fi4PYfGGLYY0yY1aWSI/iW3tP3EbxZTcqd04qS168H1gAnAQuAayVNqXDdZGLE9RGxMCIWzpw5s+LgDl4d0+PcNqtVJQW+pff0k7tduYOdWZW2AqcUvZ5Nkr/FrgRuj8Qm4DHgzArXrUvhFtTuRW9Wu0oKfMvv6buJ3qxqq4B5kuZK6gYuAVaULPMr4LUAkmYBLwI2V7huXTwWvFn9KsmeSvf0PxMRAWySdOT29AfdRG9WrYjIS7oGuAvoBG6IiA2SrkrnLwf+GrhR0jqSnfUPRcQugHLrNjI+38DKrH6VZM/BvXXg1yR765eVLFPY0/+vkj39ZytYty4+B29Wm4hYCawsmba86Pk24IJK120k38DKrH5jZk877Ol7L98sW/pc4M3qVlH2tOqefn5omP4Dwz5PZ5YxbqI3q19b38kuN5j0tHUverNsOdRE79w2q1V7F3g345llUmGMCbfOmdXOBd7MWk5uIM8EjzFhVpe2LvCHztO5Gc8sS3x1jFn92rrA59yMZ5ZJvjrGrH5tXeB9KY1ZNiVH8G6ZM6tHWxf4nC+lMcuk3MCQW+bM6tTeBX7QR/BmWeQmerP6tXWB980wzLLJY0yY1a+tC/y+gSE6BD3j2vprmFkJ96I3q19bV8a+dCMg+VpZsyxJmujdyc6sHm1d4HM+T2eWOQfHmHBum9WlvQu8z9OZZU5hjAnvvJvVp60LfN/AkAu8Wcb4FtRmjdHWBT7n83RmmeMCb9YYbV/gfTMMs9pIWixpo6RNkpaVmf8BSWvSx3pJQ5KOTec9LmldOm91I+PyGBNmjdHW1dE3wzCrjaRO4DrgfGArsErSioh4qLBMRHwe+Hy6/EXAn0XE00Vvc15E7Gp0bB5jwqwx2v8I3gXerBaLgE0RsTkiBoFbgYtHWf5S4JYjEZjHmDBrjIoKfKs25eXcyc6sVicDW4peb02nPY+kCcBi4LaiyQHcLekBSUtH+hBJSyWtlrS6t7e3osA8xoRZY4yZQa3alDeYH2ZwaNjn6cxqU+7uUDHCshcB95bk9CsjYpuk44EfSHokIu553htGXA9cD7Bw4cKR3v85PMaEWWNUcgTfkk157mlrVpetwClFr2cD20ZY9hJKcjoitqV/dwJ3kGwnGsJjTJg1RiUFviWb8nyezqwuq4B5kuZK6iYp4itKF5I0FXg18J2iaRMlTS48By4A1jcqsNxA3mNMmDVAJdWxJZvyCs143ss3q15E5CVdA9wFdAI3RMQGSVel85eni74JuDsickWrzwLuSMeA6AK+FhHfb1Rshb41HmPCrD6VVMeGNeVJKjTlPa/AV8tN9Gb1iYiVwMqSactLXt8I3FgybTNw1uGKy5e/mjVGJW1gLdmU1zdQuF+1O9mZZYkvfzVrjDGzqFWb8nwEb5ZNfS7wZg1RURa1YlPewU52vtuVWaZ4jAmzxmjbbqq+GYZZNuUGhrzjbtYAbV/g3ZRnli19A3km9TivzerVtgW+b2CI7s4Ourva9iuYWRm5QfeiN2uEtq2OSU9bn6czyxr3ojdrjDYv8N4ImGXJQH6IA0PhI3izBmjbAu+bYZhlT19/4eoYt86Z1attC3xu0EfwZlmTS29g5dw2q1/bFvg+jwVvljkeSc6scdq2wPtmGGbZ47HgzRqnrQu8b4Zhli0eBtqscdq2wPt+1WbZ4ztUmjVOWxb4iEib6L0RMMuSQ3eo9Ok3s3q1ZYHvPzDMcLgZzyxrDg0D7dw2q1dbFvhDPW29l2+WJR5jwqxx2rLAeyNgVj9JiyVtlLRJ0rIy8z8gaU36WC9pSNKxlaxbq9xAnu6uDsZ1tuWmyayltGUWuaetWX0kdQLXAUuA+cClkuYXLxMRn4+IBRGxAPgw8J8R8XQl69bKd6g0a5y2LPDuaWtWt0XApojYHBGDwK3AxaMsfylwS43rVsyDSJk1TkUFvtWa8nwzDLO6nQxsKXq9NZ32PJImAIuB22pYd6mk1ZJW9/b2jhlU38CQ729h1iBjFvhWbMo7eL9qD0hhViuVmRYjLHsRcG9EPF3tuhFxfUQsjIiFM2fOHDMoX/5q1jiVHMG3XFOeO9mZ1W0rcErR69nAthGWvYRDOV3tulXxIFJmjVNJgW+5pjx3sjOr2ypgnqS5krpJiviK0oUkTQVeDXyn2nVr4U52Zo1TSYFvuaY8N9Gb1Sci8sA1wF3Aw8A3ImKDpKskXVW06JuAuyMiN9a6jYjLnezMGqeSXeWWa8rLDebpGddBl6+VNatZRKwEVpZMW17y+kbgxkrWbYSch4E2a5hKKmTLNeW5Gc8seyKC3KBz26xRxsykiMhLKjTHdQI3FJry0vmFPf6yTXnl1q036JxHkjPLnH2DQ4THmDBrmIoyqdWa8jwWvFn2+OoYs8Zqy5PYbqI3yx4PImXWWG1Z4JOOON4ImGXJoatjvPNu1ghtmUlffNtZqNwFeGbWts44fiLfvvqVzDluQrNDMcuEtizw82ZNbnYIZtZgE7q7WHDKtGaHYZYZbVaFLsIAAAXvSURBVNlEb2ZmZqNzgTczM8sgF3gzM7MMcoE3MzPLIBd4MzOzDHKBNzMzyyBFjDTya/NI6gWeGGWRGcCuIxROtRxbbVo5Nmjt+AqxnRYRo4+13EQV5DW0x+/cihxbbdoltppyuyUL/FgkrY6Ihc2OoxzHVptWjg1aO75Wjq1arfxdHFttHFttGhGbm+jNzMwyyAXezMwsg9q1wF/f7ABG4dhq08qxQWvH18qxVauVv4tjq41jq03dsbXlOXgzMzMbXbsewZuZmdkoXODNzMwyqO0KvKTFkjZK2iRpWQvE87ikdZLWSFqdTjtW0g8k/TL9O/0IxXKDpJ2S1hdNGzEWSR9Of8eNkl7fhNg+LunX6W+3RtKFTYrtFEn/IelhSRskvTed3vTfbpTYWuK3axTn9ZjxOLerj8t5HRFt8wA6gUeB04FuYC0wv8kxPQ7MKJn2OWBZ+nwZ8NkjFMurgLOB9WPFAsxPf7/xwNz0d+08wrF9HHh/mWWPdGwnAmenzycDv0hjaPpvN0psLfHbNeg7Oq/Hjse5XX1cR31et9sR/CJgU0RsjohB4Fbg4ibHVM7FwFfS518B3ngkPjQi7gGerjCWi4FbI2IgIh4DNpH8vkcytpEc6di2R8TP0ud7gYeBk2mB326U2EZyRH+7BnFej8G5XVNcR31et1uBPxnYUvR6K6P/KEdCAHdLekDS0nTarIjYDsk/JHB806IbOZZW+S2vkfRg2sxXaCprWmyS5gC/CfyUFvvtSmKDFvvt6tCKMbd6Xo8WT6v8ni3z//Nozet2K/AqM63Z1/m9MiLOBpYAV0t6VZPjqVQr/Jb/CJwBLAC2A19IpzclNkmTgNuA90XEntEWLTPtsMZXJraW+u3q1Ioxt2teQ2v8ni3z//Nozut2K/BbgVOKXs8GtjUpFgAiYlv6dydwB0mzyQ5JJwKkf3c2L8IRY2n6bxkROyJiKCKGgS9zqMnpiMcmaRxJot0cEbenk1vitysXWyv9dg3QcjG3QV4zSjxN/z1b5f/n0Z7X7VbgVwHzJM2V1A1cAqxoVjCSJkqaXHgOXACsT2O6Il3sCuA7zYkQRollBXCJpPGS5gLzgPuPZGCFJEu9ieS3O+KxSRLwz8DDEfHFollN/+1Giq1VfrsGcV7Xpun/P0fSCv8/nde0Vy/6SHoTXkjS4/BR4KNNjuV0kp6Na4ENhXiA44AfAr9M/x57hOK5haRZ5wDJHt87R4sF+Gj6O24EljQhtn8B1gEPpv+BT2xSbL9N0tz1ILAmfVzYCr/dKLG1xG/XwO/pvB49Jud29XEd9XntW9WamZllULs10ZuZmVkFXODNzMwyyAXezMwsg1zgzczMMsgF3szMLINc4I9ykj6ajmb0YDp60TmS3idpQrNjM7PaOK8N8GVyRzNJ5wJfBF4TEQOSZpCM5vXfwMKI2NXUAM2sas5rK/AR/NHtRGBXRAwApIn/FuAk4D8k/QeApAsk3SfpZ5K+md4/uTBm9mcl3Z8+XpBOf6uk9ZLWSrqnOV/N7KjlvDbAR/BHtTShfwxMAP4N+HpE/Kekx0n39NO9/9tJ7pyUk/QhYHxE/J90uS9HxKckXQ68LSJ+V9I6YHFE/FrStIh4tilf0Owo5Ly2Ah/BH8Uiog94GbAU6AW+LuntJYu9HJgP3CtpDcm9m08rmn9L0d9z0+f3AjdK+mOg8/BEb2blOK+toKvZAVhzRcQQ8CPgR+ke+hUliwj4QURcOtJblD6PiKsknQO8AVgjaUFEPNXYyM1sJM5rAx/BH9UkvUjSvKJJC4AngL3A5HTaT4BXFp2HmyDphUXr/H7R3/vSZc6IiJ9GxMeAXTx3mEMzO4yc11bgI/ij2yTg7yVNA/LAJpJmvUuBOyVtj4jz0ua9WySNT9f7S5KRvwDGS/opyc5i4Wjg8+kGRiSjNa09It/GzMB5bSl3srOaFXfaaXYsZtYYzuvscBO9mZlZBvkI3szMLIN8BG9mZpZBLvBmZmYZ5AJvZmaWQS7wZmZmGeQCb2ZmlkH/H2DePY/t/g7dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 250\n",
    "num_examples = x_train.shape[0]\n",
    "\n",
    "train_objectives = []\n",
    "test_objectives = []\n",
    "\n",
    "for ii in range(num_steps):\n",
    "  # Indices for current batch; cycle back once we reach the end of stream.\n",
    "  batch_indices = np.arange(ii * batch_size, (ii + 1) * batch_size)\n",
    "  batch_indices = [ind % num_examples for ind in batch_indices]\n",
    "\n",
    "  # First run update ops, and then gradient update.\n",
    "  update_ops_fn()\n",
    "  optimizer.minimize(loss_fn, var_list=var_list)\n",
    "\n",
    "  # Record train and test objectives once every 10 steps.\n",
    "  if ii % 10 == 0:\n",
    "    train_objectives.append(roc_auc(model, x_train, y_train))\n",
    "    test_objectives.append(roc_auc(model, x_test, y_test))\n",
    "\n",
    "# Plot training and test objective as a function of steps.\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "ax[0].plot(np.arange(1, num_steps + 1, 10), train_objectives)\n",
    "ax[0].set_title('Train ROC-AUC')\n",
    "ax[0].set_xlabel('Steps')\n",
    "ax[1].plot(np.arange(1, num_steps + 1, 10), test_objectives)\n",
    "ax[1].set_title('Test ROC-AUC')\n",
    "ax[1].set_xlabel('Steps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1c) Accuracy Training with Plain TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_constrained_optimization.python.rates import loss\n",
    "# DEFAULT_PENALTY_LOSS = loss.HingeLoss()\n",
    "# DEFAULT_CONSTRAINT_LOSS = loss.ZeroOneLoss()\n",
    "\n",
    "# Create context with labels and predictions.\n",
    "context = tfco.rate_context(logits_fn, labels_fn)\n",
    "\n",
    "# Create optimization problem with PR-AUC as the objective. The library\n",
    "# expects a minimization objective, so we negate the Precision At Recall.\n",
    "\n",
    "# We use the f1_score rate helper which uses a Riemann approximation to the area \n",
    "# under the precision-recall curve (recall on the horizontal axis, precision on \n",
    "# the vertical axis). We would need to specify the the number of bins \n",
    "# (\"rectangles\") to use for the Riemann approximation. We also can optionally\n",
    "# specify the surrogate to be used to approximate the Precision At Recall.\n",
    "\n",
    "accuracy_rate = tfco.accuracy_rate(\n",
    "          context, \n",
    "            constraint_loss=tfco.SoftmaxCrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = tfco.RateMinimizationProblem(-accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lagrangian loss for `problem`. What we get back is a loss function, a \n",
    "# a nullary function that returns a list of update_ops that need to be run \n",
    "# before every gradient update, and the Lagrange multiplier variables internally\n",
    "# maintained by the loss function. The argument `dual_scale` is a \n",
    "# hyper-parameter that specifies the relative importance placed on updates on \n",
    "# the Lagrange multipliers.\n",
    "loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "    problem, dual_scale=1.0)\n",
    "\n",
    "# Set up optimizer and the list of variables to optimize.\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "var_list = (model.trainable_weights + problem.trainable_variables + \n",
    "            [multipliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, features, labels):\n",
    "    # Returns the Accurracy for given model, features and binary labels.\n",
    "    scores = np.argmax(model.predict(features), axis=1) \n",
    "    return metrics.accuracy_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 250\n",
    "num_examples = x_train.shape[0]\n",
    "\n",
    "train_objectives = []\n",
    "test_objectives = []\n",
    "\n",
    "for ii in range(num_steps):\n",
    "  # Indices for current batch; cycle back once we reach the end of stream.\n",
    "  batch_indices = np.arange(ii * batch_size, (ii + 1) * batch_size)\n",
    "  batch_indices = [ind % num_examples for ind in batch_indices]\n",
    "\n",
    "  # First run update ops, and then gradient update.\n",
    "  update_ops_fn()\n",
    "  optimizer.minimize(loss_fn, var_list=var_list)\n",
    "\n",
    "  # Record train and test objectives once every 10 steps.\n",
    "  if ii % 10 == 0:\n",
    "    train_objectives.append(accuracy(model, x_train, y_train))\n",
    "    test_objectives.append(accuracy(model, x_test, y_test))\n",
    "\n",
    "# Plot training and test objective as a function of steps.\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "ax[0].plot(np.arange(1, num_steps + 1, 10), train_objectives)\n",
    "ax[0].set_title('Train Accuracy-Score')\n",
    "ax[0].set_xlabel('Steps')\n",
    "ax[1].plot(np.arange(1, num_steps + 1, 10), test_objectives)\n",
    "ax[1].set_title('Test Accuracy-Score')\n",
    "ax[1].set_xlabel('Steps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1d) Precision, Recall and Accuracy Plain TF without Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,665\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "167/167 [==============================] - 0s 547us/step - loss: 0.5739\n",
      "Epoch 2/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 0.3512\n",
      "Epoch 3/250\n",
      "167/167 [==============================] - 0s 504us/step - loss: 0.0806\n",
      "Epoch 4/250\n",
      "167/167 [==============================] - 0s 564us/step - loss: 0.0057\n",
      "Epoch 5/250\n",
      "167/167 [==============================] - 0s 665us/step - loss: 0.0025\n",
      "Epoch 6/250\n",
      "167/167 [==============================] - 0s 534us/step - loss: 0.0015\n",
      "Epoch 7/250\n",
      "167/167 [==============================] - 0s 549us/step - loss: 0.0010\n",
      "Epoch 8/250\n",
      "167/167 [==============================] - 0s 527us/step - loss: 7.8181e-04\n",
      "Epoch 9/250\n",
      "167/167 [==============================] - 0s 530us/step - loss: 6.1920e-04\n",
      "Epoch 10/250\n",
      "167/167 [==============================] - 0s 522us/step - loss: 5.1134e-04\n",
      "Epoch 11/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 4.3539e-04\n",
      "Epoch 12/250\n",
      "167/167 [==============================] - 0s 501us/step - loss: 3.7557e-04\n",
      "Epoch 13/250\n",
      "167/167 [==============================] - 0s 502us/step - loss: 3.2949e-04\n",
      "Epoch 14/250\n",
      "167/167 [==============================] - 0s 537us/step - loss: 2.9342e-04\n",
      "Epoch 15/250\n",
      "167/167 [==============================] - 0s 509us/step - loss: 2.6385e-04\n",
      "Epoch 16/250\n",
      "167/167 [==============================] - 0s 507us/step - loss: 2.3861e-04\n",
      "Epoch 17/250\n",
      "167/167 [==============================] - 0s 526us/step - loss: 2.1848e-04\n",
      "Epoch 18/250\n",
      "167/167 [==============================] - 0s 528us/step - loss: 2.0047e-04\n",
      "Epoch 19/250\n",
      "167/167 [==============================] - 0s 587us/step - loss: 1.8565e-04\n",
      "Epoch 20/250\n",
      "167/167 [==============================] - 0s 511us/step - loss: 1.7191e-04\n",
      "Epoch 21/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 1.6071e-04\n",
      "Epoch 22/250\n",
      "167/167 [==============================] - 0s 553us/step - loss: 1.5069e-04\n",
      "Epoch 23/250\n",
      "167/167 [==============================] - 0s 509us/step - loss: 1.4135e-04\n",
      "Epoch 24/250\n",
      "167/167 [==============================] - 0s 578us/step - loss: 1.3362e-04\n",
      "Epoch 25/250\n",
      "167/167 [==============================] - 0s 584us/step - loss: 1.2624e-04\n",
      "Epoch 26/250\n",
      "167/167 [==============================] - 0s 507us/step - loss: 1.1962e-04\n",
      "Epoch 27/250\n",
      "167/167 [==============================] - 0s 503us/step - loss: 1.1369e-04\n",
      "Epoch 28/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 1.0819e-04\n",
      "Epoch 29/250\n",
      "167/167 [==============================] - 0s 526us/step - loss: 1.0321e-04\n",
      "Epoch 30/250\n",
      "167/167 [==============================] - 0s 643us/step - loss: 9.8522e-05\n",
      "Epoch 31/250\n",
      "167/167 [==============================] - 0s 552us/step - loss: 9.4454e-05\n",
      "Epoch 32/250\n",
      "167/167 [==============================] - 0s 517us/step - loss: 9.0501e-05\n",
      "Epoch 33/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 8.6861e-05\n",
      "Epoch 34/250\n",
      "167/167 [==============================] - 0s 528us/step - loss: 8.3564e-05\n",
      "Epoch 35/250\n",
      "167/167 [==============================] - 0s 527us/step - loss: 8.0410e-05\n",
      "Epoch 36/250\n",
      "167/167 [==============================] - 0s 531us/step - loss: 7.7506e-05\n",
      "Epoch 37/250\n",
      "167/167 [==============================] - 0s 498us/step - loss: 7.4722e-05\n",
      "Epoch 38/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 7.2358e-05\n",
      "Epoch 39/250\n",
      "167/167 [==============================] - 0s 496us/step - loss: 6.9932e-05\n",
      "Epoch 40/250\n",
      "167/167 [==============================] - 0s 511us/step - loss: 6.7639e-05\n",
      "Epoch 41/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 6.5493e-05\n",
      "Epoch 42/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 6.3537e-05\n",
      "Epoch 43/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 6.1613e-05\n",
      "Epoch 44/250\n",
      "167/167 [==============================] - 0s 509us/step - loss: 5.9873e-05\n",
      "Epoch 45/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 5.8130e-05\n",
      "Epoch 46/250\n",
      "167/167 [==============================] - 0s 515us/step - loss: 5.6493e-05\n",
      "Epoch 47/250\n",
      "167/167 [==============================] - 0s 528us/step - loss: 5.5041e-05\n",
      "Epoch 48/250\n",
      "167/167 [==============================] - 0s 517us/step - loss: 5.3557e-05\n",
      "Epoch 49/250\n",
      "167/167 [==============================] - 0s 519us/step - loss: 5.2173e-05\n",
      "Epoch 50/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 5.0846e-05\n",
      "Epoch 51/250\n",
      "167/167 [==============================] - 0s 502us/step - loss: 4.9589e-05\n",
      "Epoch 52/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 4.8372e-05\n",
      "Epoch 53/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 4.7224e-05\n",
      "Epoch 54/250\n",
      "167/167 [==============================] - 0s 496us/step - loss: 4.6137e-05\n",
      "Epoch 55/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 4.5085e-05\n",
      "Epoch 56/250\n",
      "167/167 [==============================] - 0s 493us/step - loss: 4.4079e-05\n",
      "Epoch 57/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 4.3091e-05\n",
      "Epoch 58/250\n",
      "167/167 [==============================] - 0s 508us/step - loss: 4.2189e-05\n",
      "Epoch 59/250\n",
      "167/167 [==============================] - 0s 634us/step - loss: 4.1306e-05\n",
      "Epoch 60/250\n",
      "167/167 [==============================] - 0s 511us/step - loss: 4.0437e-05\n",
      "Epoch 61/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 3.9615e-05\n",
      "Epoch 62/250\n",
      "167/167 [==============================] - 0s 496us/step - loss: 3.8833e-05\n",
      "Epoch 63/250\n",
      "167/167 [==============================] - 0s 502us/step - loss: 3.8063e-05\n",
      "Epoch 64/250\n",
      "167/167 [==============================] - 0s 493us/step - loss: 3.7325e-05\n",
      "Epoch 65/250\n",
      "167/167 [==============================] - 0s 512us/step - loss: 3.6633e-05\n",
      "Epoch 66/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 3.5944e-05\n",
      "Epoch 67/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 3.5269e-05\n",
      "Epoch 68/250\n",
      "167/167 [==============================] - 0s 511us/step - loss: 3.4647e-05\n",
      "Epoch 69/250\n",
      "167/167 [==============================] - 0s 498us/step - loss: 3.4033e-05\n",
      "Epoch 70/250\n",
      "167/167 [==============================] - 0s 507us/step - loss: 3.3420e-05\n",
      "Epoch 71/250\n",
      "167/167 [==============================] - 0s 524us/step - loss: 3.2849e-05\n",
      "Epoch 72/250\n",
      "167/167 [==============================] - 0s 503us/step - loss: 3.2280e-05\n",
      "Epoch 73/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 3.1732e-05\n",
      "Epoch 74/250\n",
      "167/167 [==============================] - 0s 493us/step - loss: 3.1228e-05\n",
      "Epoch 75/250\n",
      "167/167 [==============================] - 0s 532us/step - loss: 3.0701e-05\n",
      "Epoch 76/250\n",
      "167/167 [==============================] - 0s 621us/step - loss: 3.0223e-05\n",
      "Epoch 77/250\n",
      "167/167 [==============================] - 0s 519us/step - loss: 2.9736e-05\n",
      "Epoch 78/250\n",
      "167/167 [==============================] - 0s 641us/step - loss: 2.9276e-05\n",
      "Epoch 79/250\n",
      "167/167 [==============================] - 0s 591us/step - loss: 2.8817e-05\n",
      "Epoch 80/250\n",
      "167/167 [==============================] - 0s 540us/step - loss: 2.8387e-05\n",
      "Epoch 81/250\n",
      "167/167 [==============================] - 0s 510us/step - loss: 2.7961e-05\n",
      "Epoch 82/250\n",
      "167/167 [==============================] - 0s 622us/step - loss: 2.7543e-05\n",
      "Epoch 83/250\n",
      "167/167 [==============================] - 0s 566us/step - loss: 2.7138e-05\n",
      "Epoch 84/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 2.6740e-05\n",
      "Epoch 85/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 526us/step - loss: 2.6362e-05\n",
      "Epoch 86/250\n",
      "167/167 [==============================] - 0s 537us/step - loss: 2.5993e-05\n",
      "Epoch 87/250\n",
      "167/167 [==============================] - 0s 535us/step - loss: 2.5635e-05\n",
      "Epoch 88/250\n",
      "167/167 [==============================] - 0s 536us/step - loss: 2.5276e-05\n",
      "Epoch 89/250\n",
      "167/167 [==============================] - 0s 699us/step - loss: 2.4937e-05\n",
      "Epoch 90/250\n",
      "167/167 [==============================] - 0s 850us/step - loss: 2.4600e-05\n",
      "Epoch 91/250\n",
      "167/167 [==============================] - 0s 683us/step - loss: 2.4278e-05\n",
      "Epoch 92/250\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 2.3950e-05\n",
      "Epoch 93/250\n",
      "167/167 [==============================] - 0s 751us/step - loss: 2.3643e-05\n",
      "Epoch 94/250\n",
      "167/167 [==============================] - 0s 709us/step - loss: 2.3344e-05\n",
      "Epoch 95/250\n",
      "167/167 [==============================] - 0s 815us/step - loss: 2.3034e-05\n",
      "Epoch 96/250\n",
      "167/167 [==============================] - 0s 981us/step - loss: 2.2757e-05\n",
      "Epoch 97/250\n",
      "167/167 [==============================] - 0s 667us/step - loss: 2.2474e-05\n",
      "Epoch 98/250\n",
      "167/167 [==============================] - 0s 692us/step - loss: 2.2196e-05\n",
      "Epoch 99/250\n",
      "167/167 [==============================] - 0s 688us/step - loss: 2.1925e-05\n",
      "Epoch 100/250\n",
      "167/167 [==============================] - 0s 779us/step - loss: 2.1662e-05\n",
      "Epoch 101/250\n",
      "167/167 [==============================] - 0s 720us/step - loss: 2.1403e-05\n",
      "Epoch 102/250\n",
      "167/167 [==============================] - 0s 676us/step - loss: 2.1150e-05\n",
      "Epoch 103/250\n",
      "167/167 [==============================] - 0s 694us/step - loss: 2.0901e-05\n",
      "Epoch 104/250\n",
      "167/167 [==============================] - 0s 546us/step - loss: 2.0665e-05\n",
      "Epoch 105/250\n",
      "167/167 [==============================] - 0s 511us/step - loss: 2.0425e-05\n",
      "Epoch 106/250\n",
      "167/167 [==============================] - 0s 532us/step - loss: 2.0199e-05\n",
      "Epoch 107/250\n",
      "167/167 [==============================] - 0s 527us/step - loss: 1.9970e-05\n",
      "Epoch 108/250\n",
      "167/167 [==============================] - 0s 504us/step - loss: 1.9750e-05\n",
      "Epoch 109/250\n",
      "167/167 [==============================] - 0s 501us/step - loss: 1.9532e-05\n",
      "Epoch 110/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 1.9318e-05\n",
      "Epoch 111/250\n",
      "167/167 [==============================] - 0s 530us/step - loss: 1.9113e-05\n",
      "Epoch 112/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 1.8883e-05\n",
      "Epoch 113/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 1.8718e-05\n",
      "Epoch 114/250\n",
      "167/167 [==============================] - 0s 598us/step - loss: 1.8513e-05\n",
      "Epoch 115/250\n",
      "167/167 [==============================] - 0s 654us/step - loss: 1.8314e-05\n",
      "Epoch 116/250\n",
      "167/167 [==============================] - 0s 669us/step - loss: 1.8129e-05\n",
      "Epoch 117/250\n",
      "167/167 [==============================] - 0s 612us/step - loss: 1.7939e-05\n",
      "Epoch 118/250\n",
      "167/167 [==============================] - 0s 514us/step - loss: 1.7758e-05\n",
      "Epoch 119/250\n",
      "167/167 [==============================] - 0s 521us/step - loss: 1.7580e-05\n",
      "Epoch 120/250\n",
      "167/167 [==============================] - 0s 493us/step - loss: 1.7404e-05\n",
      "Epoch 121/250\n",
      "167/167 [==============================] - 0s 508us/step - loss: 1.7233e-05\n",
      "Epoch 122/250\n",
      "167/167 [==============================] - 0s 512us/step - loss: 1.7061e-05\n",
      "Epoch 123/250\n",
      "167/167 [==============================] - 0s 613us/step - loss: 1.6897e-05\n",
      "Epoch 124/250\n",
      "167/167 [==============================] - 0s 526us/step - loss: 1.6733e-05\n",
      "Epoch 125/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 1.6573e-05\n",
      "Epoch 126/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 1.6416e-05\n",
      "Epoch 127/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 1.6266e-05\n",
      "Epoch 128/250\n",
      "167/167 [==============================] - 0s 513us/step - loss: 1.6109e-05\n",
      "Epoch 129/250\n",
      "167/167 [==============================] - 0s 527us/step - loss: 1.5956e-05\n",
      "Epoch 130/250\n",
      "167/167 [==============================] - 0s 519us/step - loss: 1.5817e-05\n",
      "Epoch 131/250\n",
      "167/167 [==============================] - 0s 503us/step - loss: 1.5673e-05\n",
      "Epoch 132/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 1.5531e-05\n",
      "Epoch 133/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 1.5392e-05\n",
      "Epoch 134/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 1.5255e-05\n",
      "Epoch 135/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 1.5119e-05\n",
      "Epoch 136/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 1.4989e-05\n",
      "Epoch 137/250\n",
      "167/167 [==============================] - 0s 501us/step - loss: 1.4859e-05\n",
      "Epoch 138/250\n",
      "167/167 [==============================] - 0s 503us/step - loss: 1.4729e-05\n",
      "Epoch 139/250\n",
      "167/167 [==============================] - 0s 490us/step - loss: 1.4604e-05\n",
      "Epoch 140/250\n",
      "167/167 [==============================] - 0s 512us/step - loss: 1.4478e-05\n",
      "Epoch 141/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 1.4357e-05\n",
      "Epoch 142/250\n",
      "167/167 [==============================] - 0s 653us/step - loss: 1.4239e-05\n",
      "Epoch 143/250\n",
      "167/167 [==============================] - 0s 504us/step - loss: 1.4120e-05\n",
      "Epoch 144/250\n",
      "167/167 [==============================] - 0s 513us/step - loss: 1.4002e-05\n",
      "Epoch 145/250\n",
      "167/167 [==============================] - 0s 590us/step - loss: 1.3887e-05\n",
      "Epoch 146/250\n",
      "167/167 [==============================] - 0s 667us/step - loss: 1.3771e-05\n",
      "Epoch 147/250\n",
      "167/167 [==============================] - 0s 717us/step - loss: 1.3662e-05\n",
      "Epoch 148/250\n",
      "167/167 [==============================] - 0s 617us/step - loss: 1.3559e-05\n",
      "Epoch 149/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 1.3446e-05\n",
      "Epoch 150/250\n",
      "167/167 [==============================] - 0s 504us/step - loss: 1.3339e-05\n",
      "Epoch 151/250\n",
      "167/167 [==============================] - 0s 497us/step - loss: 1.3234e-05\n",
      "Epoch 152/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 1.3132e-05\n",
      "Epoch 153/250\n",
      "167/167 [==============================] - 0s 494us/step - loss: 1.3029e-05\n",
      "Epoch 154/250\n",
      "167/167 [==============================] - 0s 525us/step - loss: 1.2928e-05\n",
      "Epoch 155/250\n",
      "167/167 [==============================] - 0s 522us/step - loss: 1.2829e-05\n",
      "Epoch 156/250\n",
      "167/167 [==============================] - 0s 533us/step - loss: 1.2730e-05\n",
      "Epoch 157/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 1.2637e-05\n",
      "Epoch 158/250\n",
      "167/167 [==============================] - 0s 502us/step - loss: 1.2540e-05\n",
      "Epoch 159/250\n",
      "167/167 [==============================] - 0s 532us/step - loss: 1.2447e-05\n",
      "Epoch 160/250\n",
      "167/167 [==============================] - 0s 712us/step - loss: 1.2356e-05\n",
      "Epoch 161/250\n",
      "167/167 [==============================] - 0s 690us/step - loss: 1.2264e-05\n",
      "Epoch 162/250\n",
      "167/167 [==============================] - 0s 632us/step - loss: 1.2173e-05\n",
      "Epoch 163/250\n",
      "167/167 [==============================] - 0s 535us/step - loss: 1.2088e-05\n",
      "Epoch 164/250\n",
      "167/167 [==============================] - 0s 536us/step - loss: 1.1998e-05\n",
      "Epoch 165/250\n",
      "167/167 [==============================] - 0s 499us/step - loss: 1.1914e-05\n",
      "Epoch 166/250\n",
      "167/167 [==============================] - 0s 509us/step - loss: 1.1828e-05\n",
      "Epoch 167/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 1.1745e-05\n",
      "Epoch 168/250\n",
      "167/167 [==============================] - 0s 514us/step - loss: 1.1661e-05\n",
      "Epoch 169/250\n",
      "167/167 [==============================] - 0s 539us/step - loss: 1.1580e-05\n",
      "Epoch 170/250\n",
      "167/167 [==============================] - 0s 548us/step - loss: 1.1502e-05\n",
      "Epoch 171/250\n",
      "167/167 [==============================] - 0s 468us/step - loss: 1.1423e-05\n",
      "Epoch 172/250\n",
      "167/167 [==============================] - 0s 523us/step - loss: 1.1344e-05\n",
      "Epoch 173/250\n",
      "167/167 [==============================] - 0s 500us/step - loss: 1.1264e-05\n",
      "Epoch 174/250\n",
      "167/167 [==============================] - 0s 495us/step - loss: 1.1190e-05\n",
      "Epoch 175/250\n",
      "167/167 [==============================] - 0s 517us/step - loss: 1.1114e-05\n",
      "Epoch 176/250\n",
      "167/167 [==============================] - 0s 575us/step - loss: 1.1039e-05\n",
      "Epoch 177/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 1.0965e-05\n",
      "Epoch 178/250\n",
      "167/167 [==============================] - 0s 562us/step - loss: 1.0895e-05\n",
      "Epoch 179/250\n",
      "167/167 [==============================] - 0s 550us/step - loss: 1.0817e-05\n",
      "Epoch 180/250\n",
      "167/167 [==============================] - 0s 505us/step - loss: 1.0752e-05\n",
      "Epoch 181/250\n",
      "167/167 [==============================] - 0s 522us/step - loss: 1.0682e-05\n",
      "Epoch 182/250\n",
      "167/167 [==============================] - 0s 576us/step - loss: 1.0611e-05\n",
      "Epoch 183/250\n",
      "167/167 [==============================] - 0s 585us/step - loss: 1.0544e-05\n",
      "Epoch 184/250\n",
      "167/167 [==============================] - 0s 595us/step - loss: 1.0478e-05\n",
      "Epoch 185/250\n",
      "167/167 [==============================] - 0s 646us/step - loss: 1.0411e-05\n",
      "Epoch 186/250\n",
      "167/167 [==============================] - 0s 654us/step - loss: 1.0345e-05\n",
      "Epoch 187/250\n",
      "167/167 [==============================] - 0s 559us/step - loss: 1.0276e-05\n",
      "Epoch 188/250\n",
      "167/167 [==============================] - 0s 645us/step - loss: 1.0216e-05\n",
      "Epoch 189/250\n",
      "167/167 [==============================] - 0s 628us/step - loss: 1.0152e-05\n",
      "Epoch 190/250\n",
      "167/167 [==============================] - 0s 544us/step - loss: 1.0089e-05\n",
      "Epoch 191/250\n",
      "167/167 [==============================] - 0s 569us/step - loss: 1.0029e-05\n",
      "Epoch 192/250\n",
      "167/167 [==============================] - 0s 586us/step - loss: 9.9667e-06\n",
      "Epoch 193/250\n",
      "167/167 [==============================] - 0s 580us/step - loss: 9.9054e-06\n",
      "Epoch 194/250\n",
      "167/167 [==============================] - 0s 573us/step - loss: 9.8454e-06\n",
      "Epoch 195/250\n",
      "167/167 [==============================] - 0s 580us/step - loss: 9.7862e-06\n",
      "Epoch 196/250\n",
      "167/167 [==============================] - 0s 607us/step - loss: 9.7286e-06\n",
      "Epoch 197/250\n",
      "167/167 [==============================] - 0s 577us/step - loss: 9.6688e-06\n",
      "Epoch 198/250\n",
      "167/167 [==============================] - 0s 798us/step - loss: 9.6137e-06\n",
      "Epoch 199/250\n",
      "167/167 [==============================] - 0s 731us/step - loss: 9.5540e-06\n",
      "Epoch 200/250\n",
      "167/167 [==============================] - 0s 586us/step - loss: 9.4996e-06\n",
      "Epoch 201/250\n",
      "167/167 [==============================] - 0s 554us/step - loss: 9.4447e-06\n",
      "Epoch 202/250\n",
      "167/167 [==============================] - 0s 682us/step - loss: 9.3899e-06\n",
      "Epoch 203/250\n",
      "167/167 [==============================] - 0s 888us/step - loss: 9.3348e-06\n",
      "Epoch 204/250\n",
      "167/167 [==============================] - 0s 781us/step - loss: 9.2820e-06\n",
      "Epoch 205/250\n",
      "167/167 [==============================] - 0s 703us/step - loss: 9.2274e-06\n",
      "Epoch 206/250\n",
      "167/167 [==============================] - 0s 559us/step - loss: 9.1762e-06\n",
      "Epoch 207/250\n",
      "167/167 [==============================] - 0s 553us/step - loss: 9.1245e-06\n",
      "Epoch 208/250\n",
      "167/167 [==============================] - 0s 751us/step - loss: 9.0717e-06\n",
      "Epoch 209/250\n",
      "167/167 [==============================] - 0s 638us/step - loss: 9.0216e-06\n",
      "Epoch 210/250\n",
      "167/167 [==============================] - 0s 531us/step - loss: 8.9708e-06\n",
      "Epoch 211/250\n",
      "167/167 [==============================] - 0s 599us/step - loss: 8.9216e-06\n",
      "Epoch 212/250\n",
      "167/167 [==============================] - 0s 766us/step - loss: 8.8725e-06\n",
      "Epoch 213/250\n",
      "167/167 [==============================] - 0s 593us/step - loss: 8.8236e-06\n",
      "Epoch 214/250\n",
      "167/167 [==============================] - 0s 526us/step - loss: 8.7758e-06\n",
      "Epoch 215/250\n",
      "167/167 [==============================] - 0s 558us/step - loss: 8.7275e-06\n",
      "Epoch 216/250\n",
      "167/167 [==============================] - 0s 585us/step - loss: 8.6802e-06\n",
      "Epoch 217/250\n",
      "167/167 [==============================] - 0s 514us/step - loss: 8.6341e-06\n",
      "Epoch 218/250\n",
      "167/167 [==============================] - 0s 556us/step - loss: 8.5871e-06\n",
      "Epoch 219/250\n",
      "167/167 [==============================] - 0s 531us/step - loss: 8.5426e-06\n",
      "Epoch 220/250\n",
      "167/167 [==============================] - 0s 521us/step - loss: 8.4962e-06\n",
      "Epoch 221/250\n",
      "167/167 [==============================] - 0s 551us/step - loss: 8.4519e-06\n",
      "Epoch 222/250\n",
      "167/167 [==============================] - 0s 623us/step - loss: 8.4068e-06\n",
      "Epoch 223/250\n",
      "167/167 [==============================] - 0s 554us/step - loss: 8.3636e-06\n",
      "Epoch 224/250\n",
      "167/167 [==============================] - 0s 727us/step - loss: 8.3189e-06\n",
      "Epoch 225/250\n",
      "167/167 [==============================] - 0s 544us/step - loss: 8.2757e-06\n",
      "Epoch 226/250\n",
      "167/167 [==============================] - 0s 536us/step - loss: 8.2336e-06\n",
      "Epoch 227/250\n",
      "167/167 [==============================] - 0s 725us/step - loss: 8.1921e-06\n",
      "Epoch 228/250\n",
      "167/167 [==============================] - 0s 549us/step - loss: 8.1487e-06\n",
      "Epoch 229/250\n",
      "167/167 [==============================] - 0s 560us/step - loss: 8.1069e-06\n",
      "Epoch 230/250\n",
      "167/167 [==============================] - 0s 649us/step - loss: 8.0652e-06\n",
      "Epoch 231/250\n",
      "167/167 [==============================] - 0s 598us/step - loss: 8.0246e-06\n",
      "Epoch 232/250\n",
      "167/167 [==============================] - 0s 609us/step - loss: 7.9831e-06\n",
      "Epoch 233/250\n",
      "167/167 [==============================] - 0s 587us/step - loss: 7.9452e-06\n",
      "Epoch 234/250\n",
      "167/167 [==============================] - 0s 544us/step - loss: 7.9054e-06\n",
      "Epoch 235/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 7.8656e-06\n",
      "Epoch 236/250\n",
      "167/167 [==============================] - 0s 564us/step - loss: 7.8267e-06\n",
      "Epoch 237/250\n",
      "167/167 [==============================] - 0s 696us/step - loss: 7.7878e-06\n",
      "Epoch 238/250\n",
      "167/167 [==============================] - 0s 534us/step - loss: 7.7500e-06\n",
      "Epoch 239/250\n",
      "167/167 [==============================] - 0s 533us/step - loss: 7.7119e-06\n",
      "Epoch 240/250\n",
      "167/167 [==============================] - 0s 552us/step - loss: 7.6745e-06\n",
      "Epoch 241/250\n",
      "167/167 [==============================] - 0s 520us/step - loss: 7.6372e-06\n",
      "Epoch 242/250\n",
      "167/167 [==============================] - 0s 567us/step - loss: 7.6003e-06\n",
      "Epoch 243/250\n",
      "167/167 [==============================] - 0s 544us/step - loss: 7.5636e-06\n",
      "Epoch 244/250\n",
      "167/167 [==============================] - 0s 507us/step - loss: 7.5282e-06\n",
      "Epoch 245/250\n",
      "167/167 [==============================] - 0s 692us/step - loss: 7.4917e-06\n",
      "Epoch 246/250\n",
      "167/167 [==============================] - 0s 596us/step - loss: 7.4561e-06\n",
      "Epoch 247/250\n",
      "167/167 [==============================] - 0s 612us/step - loss: 7.4208e-06\n",
      "Epoch 248/250\n",
      "167/167 [==============================] - 0s 558us/step - loss: 7.3865e-06\n",
      "Epoch 249/250\n",
      "167/167 [==============================] - 0s 542us/step - loss: 7.3519e-06\n",
      "Epoch 250/250\n",
      "167/167 [==============================] - 0s 518us/step - loss: 7.3175e-06\n",
      "[0 0 0 ... 0 0 0] [0. 0. 0. ... 0. 0. 0.]\n",
      "Precision = [0.78687295 0.        ]\n",
      "Recall= [1. 0.]\n",
      "F1 Score = [0.88072624 0.        ]\n",
      "Accuracy0.7868729488982653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create linear Keras model.\n",
    "layers = []\n",
    "layers.append(tf.keras.Input(shape=(x_train.shape[-1],)))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(1))\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "\n",
    "#var_list = (\n",
    "    #optimizer.trainable_variables())\n",
    "    \n",
    "# for ii in range(num_steps):\n",
    "#   # Indices for current batch; cycle back once we reach the end of stream.\n",
    "#   batch_indices = np.arange(ii * batch_size, (ii + 1) * batch_size)\n",
    "#   batch_indices = [ind % num_examples for ind in batch_indices]\n",
    "#   loss_fn =lambda y_true, y_pred: tf.keras.losses.binary_crossentropy(\n",
    "#       y_true, y_pred, from_logits=True)\n",
    "\n",
    "#   #First run update ops, and then gradient update.\n",
    "#   update_ops_fn()\n",
    "#   optimizer.minimize(loss_fn, var_list=model.trainable_weights, y_true, y_pred)\n",
    "\n",
    "\n",
    "loss = lambda y_true, y_pred: tf.keras.losses.binary_crossentropy(\n",
    "    y_true, y_pred, from_logits=True)\n",
    "\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=loss)\n",
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=250)\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(pred_labels, y_test)\n",
    "\n",
    "\n",
    "\n",
    "precisions, recall, f1_score, true_sum = metrics.precision_recall_fscore_support(y_test, pred_labels)\n",
    "\n",
    "print(\"Precision =\", precisions)\n",
    "print(\"Recall=\", recall)\n",
    "print(\"F1 Score =\", f1_score)\n",
    "accuracy_score = metrics.accuracy_score(y_test, pred_labels)\n",
    "print('Accuracy' + str(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTGOcqe0pO5a"
   },
   "source": [
    "# (2a) PR-AUC Training with Custom Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uppYKix2-SdA"
   },
   "source": [
    "We next show how one can use TFCO to optimize PR-AUC using custom tf.Estimators.\n",
    "\n",
    "We first create `feature_columns` to convert the dataset into a format that can be processed by an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_klY8Dqueag_"
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for feature_name in x_train_df.columns:\n",
    "  feature_columns.append(\n",
    "      tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyaRvuOXAGt-"
   },
   "source": [
    "We next construct the input functions that return the data to be used by the estimator for training/evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoEGUpg9pTdD"
   },
   "outputs": [],
   "source": [
    "def make_input_fn(\n",
    "    data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_fn():\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    return ds\n",
    "  return input_fn\n",
    "\n",
    "train_input_fn = make_input_fn(x_train_df, y_train_df, num_epochs=25)\n",
    "test_input_fn = make_input_fn(x_test_df, y_test_df, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSw7IHgKA5NC"
   },
   "source": [
    "We then write the model function that is used by the estimator to create the model, loss, optimizers and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUD8PAddptO7"
   },
   "outputs": [],
   "source": [
    "def make_model_fn_pr_auc(feature_columns):\n",
    "  # Returns model_fn.\n",
    "\n",
    "  def model_fn(features, labels, mode):\n",
    "    # Create model from features.\n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    logits = model(features)\n",
    "\n",
    "    # Baseline cross-entropy loss.\n",
    "    baseline_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    baseline_loss = baseline_loss_fn(labels, logits)\n",
    "\n",
    "    # As a slight variant from the above previous training, we will optimize a \n",
    "    # weighted combination of PR-AUC and the baseline loss.\n",
    "    baseline_coef = 0.2\n",
    "    \n",
    "    train_op = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # Set up PR-AUC optimization problem.\n",
    "      # Create context with labels and predictions.\n",
    "      context = tfco.rate_context(logits, labels)\n",
    "\n",
    "      # Create optimization problem with PR-AUC as the objective. The library\n",
    "      # expects a minimization objective, so we negate the PR-AUC. We optimize\n",
    "      # a convex combination of (negative) PR-AUC and the baseline loss (wrapped\n",
    "      # in a rate object).\n",
    "      pr_auc_rate = tfco.pr_auc(\n",
    "          context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "      problem = tfco.RateMinimizationProblem(\n",
    "          (1 - baseline_coef) * (-pr_auc_rate) + \n",
    "          baseline_coef * tfco.wrap_rate(baseline_loss))\n",
    "\n",
    "      # Create Lagrangian loss for `problem`. What we get back is a loss \n",
    "      # function, a nullary function that returns a list of update_ops that \n",
    "      # need to be run before every gradient update, and the Lagrange \n",
    "      # multipliers maintained internally by the loss.\n",
    "      # The argument `dual_scale` is a hyper-parameter that specifies the  \n",
    "      # relative importance placed on updates on the Lagrange multipliers.\n",
    "      loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "          problem, dual_scale=1.0)\n",
    "      \n",
    "      # Set up optimizer and the list of variables to optimize the loss.\n",
    "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "      optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
    "      \n",
    "      # Get minimize op and group with update_ops.\n",
    "      var_list = (\n",
    "          model.trainable_weights + problem.trainable_variables + [multipliers])\n",
    "      minimize_op = optimizer.get_updates(loss_fn(), var_list)\n",
    "      update_ops = update_ops_fn()\n",
    "      train_op = tf.group(*update_ops, minimize_op)\n",
    "\n",
    "    # Evaluate PR-AUC.\n",
    "    pr_auc_metric = tf.keras.metrics.AUC(curve='PR')\n",
    "    pr_auc_metric.update_state(labels, tf.sigmoid(logits))\n",
    "\n",
    "    # We do not use the Lagrangian loss for evaluation/bookkeeping\n",
    "    # purposes as it depends on some internal variables that may not be\n",
    "    # set properly during evaluation time. We instead pass loss=baseline_loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        predictions=logits, \n",
    "        loss=baseline_loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'PR-AUC': pr_auc_metric})\n",
    "    \n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tfco_tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.164241, step = 0\n",
      "INFO:tensorflow:global_step/sec: 63.4201\n",
      "INFO:tensorflow:loss = 0.39134467, step = 100 (1.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.811\n",
      "INFO:tensorflow:loss = 0.356475, step = 200 (0.405 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n",
      "INFO:tensorflow:Saving checkpoints for 250 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n",
      "INFO:tensorflow:Loss for final step: 0.34849274.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7fa43dc282d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary model directory.\n",
    "model_dir = \"tfco_tmp\"\n",
    "if os.path.exists(model_dir):\n",
    "  shutil.rmtree(model_dir)\n",
    "\n",
    "# Train estimator.\n",
    "estimator_lin = tf.estimator.Estimator(\n",
    "    make_model_fn_pr_auc(feature_columns), model_dir=model_dir)\n",
    "estimator_lin.train(train_input_fn, steps=250) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-08T11:33:25Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tfco_tmp/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44148s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-08-11:33:25\n",
      "INFO:tensorflow:Saving dict for global step 250: PR-AUC = 0.9554919, global_step = 250, loss = 0.39580733\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: tfco_tmp/model.ckpt-250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PR-AUC': 0.9554919, 'loss': 0.39580733, 'global_step': 250}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_lin.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2b) ROC-AUC Training with Custom Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_fn_roc_auc(feature_columns):\n",
    "  # Returns model_fn.\n",
    "\n",
    "  def model_fn(features, labels, mode):\n",
    "    # Create model from features.\n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    logits = model(features)\n",
    "\n",
    "    # Baseline cross-entropy loss.\n",
    "    baseline_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    baseline_loss = baseline_loss_fn(labels, logits)\n",
    "\n",
    "    # As a slight variant from the above previous training, we will optimize a \n",
    "    # weighted combination of ROC-AUC and the baseline loss.\n",
    "    baseline_coef = 0.2\n",
    "    \n",
    "    train_op = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # Set up ROC-AUC optimization problem.\n",
    "      # Create context with labels and predictions.\n",
    "      context = tfco.rate_context(logits, labels)\n",
    "\n",
    "      # Create optimization problem with ROC-AUC as the objective. The library\n",
    "      # expects a minimization objective, so we negate the PR-AUC. We optimize\n",
    "      # a convex combination of (negative) ROC-AUC and the baseline loss (wrapped\n",
    "      # in a rate object).\n",
    "      roc_auc_rate = tfco.roc_auc(\n",
    "          context, bins=10, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "      problem = tfco.RateMinimizationProblem(\n",
    "          (1 - baseline_coef) * (-roc_auc_rate) + \n",
    "          baseline_coef * tfco.wrap_rate(baseline_loss))\n",
    "\n",
    "      # Create Lagrangian loss for `problem`. What we get back is a loss \n",
    "      # function, a nullary function that returns a list of update_ops that \n",
    "      # need to be run before every gradient update, and the Lagrange \n",
    "      # multipliers maintained internally by the loss.\n",
    "      # The argument `dual_scale` is a hyper-parameter that specifies the  \n",
    "      # relative importance placed on updates on the Lagrange multipliers.\n",
    "      loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "          problem, dual_scale=1.0)\n",
    "      \n",
    "      # Set up optimizer and the list of variables to optimize the loss.\n",
    "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "      optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
    "      \n",
    "      # Get minimize op and group with update_ops.\n",
    "      var_list = (\n",
    "          model.trainable_weights + problem.trainable_variables + [multipliers])\n",
    "      minimize_op = optimizer.get_updates(loss_fn(), var_list)\n",
    "      update_ops = update_ops_fn()\n",
    "      train_op = tf.group(*update_ops, minimize_op)\n",
    "\n",
    "    # Evaluate ROC-AUC.\n",
    "    roc_auc_metric = tf.keras.metrics.AUC(curve='ROC')\n",
    "    roc_auc_metric.update_state(labels, tf.sigmoid(logits))\n",
    "\n",
    "    # We do not use the Lagrangian loss for evaluation/bookkeeping\n",
    "    # purposes as it depends on some internal variables that may not be\n",
    "    # set properly during evaluation time. We instead pass loss=baseline_loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        predictions=logits, \n",
    "        loss=baseline_loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'ROC-AUC': roc_auc_metric})\n",
    "    \n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kc3_ftIBC6Y"
   },
   "source": [
    "We are now ready to train the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "colab_type": "code",
    "id": "TImVz7WMp-Nb",
    "outputId": "d8f64525-dba6-46b2-a7e6-39d05c0a5d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tfco_tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 8.582456, step = 0\n",
      "INFO:tensorflow:global_step/sec: 77.6791\n",
      "INFO:tensorflow:loss = 0.48806846, step = 100 (1.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.396\n",
      "INFO:tensorflow:loss = 0.3783787, step = 200 (0.343 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n",
      "INFO:tensorflow:Saving checkpoints for 250 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n",
      "INFO:tensorflow:Loss for final step: 0.36281124.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7fa424a7a350>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary model directory.\n",
    "model_dir = \"tfco_tmp\"\n",
    "if os.path.exists(model_dir):\n",
    "  shutil.rmtree(model_dir)\n",
    "\n",
    "# Train estimator.\n",
    "estimator_lin = tf.estimator.Estimator(\n",
    "    make_model_fn_roc_auc(feature_columns), model_dir=model_dir)\n",
    "estimator_lin.train(train_input_fn, steps=250) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYkWYCgvBGJA"
   },
   "source": [
    "Finally, we evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "iiB6oG2fqC7S",
    "outputId": "043ce405-99f7-48a7-d2de-d60708017a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-08T11:33:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tfco_tmp/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45977s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-08-11:33:34\n",
      "INFO:tensorflow:Saving dict for global step 250: ROC-AUC = 0.9972118, global_step = 250, loss = 0.42947346\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: tfco_tmp/model.ckpt-250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC-AUC': 0.9972118, 'loss': 0.42947346, 'global_step': 250}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_lin.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xU1eK4GVKd_"
   },
   "source": [
    "## Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjzlHyFnC7d3"
   },
   "source": [
    "Before closing, we point out that there are three main hyper-paramters you may want to tune to improve the PR-AUC training:\n",
    "\n",
    "- `learning_rate`\n",
    "- `dual_scale`\n",
    "- `baseline_coeff`\n",
    "\n",
    "We may also be interested in exploring helpers for other similar metrics that TFCO allows you to optimize: Lets expore them in the beneatah cells.\n",
    "- `tfco.precision_at_recall`\n",
    "- `tfco.recall_at_precision`\n",
    "- `tfco.inverse_precision_at_recall`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2c) Precision_At_Recall Training with Custom Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_fn_precision_at_recall(feature_columns):\n",
    "  # Returns model_fn.\n",
    "\n",
    "  def model_fn(features, labels, mode):\n",
    "    # Create model from features.\n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    logits = model(features)\n",
    "\n",
    "    # Baseline cross-entropy loss.\n",
    "    baseline_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    baseline_loss = baseline_loss_fn(labels, logits)\n",
    "\n",
    "    # As a slight variant from the above previous training, we will optimize a \n",
    "    # weighted combination of Precision At Recall and the baseline loss.\n",
    "    baseline_coef = 0.2\n",
    "    \n",
    "    train_op = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # Set up ROC-AUC optimization problem.\n",
    "      # Create context with labels and predictions.\n",
    "      context = tfco.rate_context(logits, labels)\n",
    "\n",
    "      # Create optimization problem with Precision At Recall as the objective. The library\n",
    "      # expects a minimization objective, so we negate the Precision At Recall. We optimize\n",
    "      # a convex combination of (negative) Precision At Recall and the baseline loss (wrapped\n",
    "      # in a rate object).\n",
    "      precision_at_recall_rate = tfco.precision_at_recall(\n",
    "          context, recall_target=0.9, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "      problem = tfco.RateMinimizationProblem(\n",
    "          (1 - baseline_coef) * (-precision_at_recall_rate) + \n",
    "          baseline_coef * tfco.wrap_rate(baseline_loss))\n",
    "\n",
    "      # Create Lagrangian loss for `problem`. What we get back is a loss \n",
    "      # function, a nullary function that returns a list of update_ops that \n",
    "      # need to be run before every gradient update, and the Lagrange \n",
    "      # multipliers maintained internally by the loss.\n",
    "      # The argument `dual_scale` is a hyper-parameter that specifies the  \n",
    "      # relative importance placed on updates on the Lagrange multipliers.\n",
    "      loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "          problem, dual_scale=1.0)\n",
    "      \n",
    "      # Set up optimizer and the list of variables to optimize the loss.\n",
    "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "      optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
    "      \n",
    "      # Get minimize op and group with update_ops.\n",
    "      var_list = (\n",
    "          model.trainable_weights + problem.trainable_variables + [multipliers])\n",
    "      minimize_op = optimizer.get_updates(loss_fn(), var_list)\n",
    "      update_ops = update_ops_fn()\n",
    "      train_op = tf.group(*update_ops, minimize_op)\n",
    "\n",
    "    # Evaluate Precision At Recall.\n",
    "    precision_at_recall_metric = tf.keras.metrics.PrecisionAtRecall(0.6)\n",
    "    precision_at_recall_metric.update_state(labels, tf.sigmoid(logits))\n",
    "\n",
    "    # We do not use the Lagrangian loss for evaluation/bookkeeping\n",
    "    # purposes as it depends on some internal variables that may not be\n",
    "    # set properly during evaluation time. We instead pass loss=baseline_loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        predictions=logits, \n",
    "        loss=baseline_loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'Precision-At-Recall': precision_at_recall_metric})\n",
    "    \n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tfco_tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 4.867975, step = 0\n",
      "INFO:tensorflow:global_step/sec: 383.565\n",
      "INFO:tensorflow:loss = 0.297989, step = 100 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 924.717\n",
      "INFO:tensorflow:loss = 0.36816376, step = 200 (0.108 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n",
      "INFO:tensorflow:Saving checkpoints for 250 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n",
      "INFO:tensorflow:Loss for final step: 0.49796444.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7fa4249804d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary model directory.\n",
    "model_dir = \"tfco_tmp\"\n",
    "if os.path.exists(model_dir):\n",
    "  shutil.rmtree(model_dir)\n",
    "\n",
    "# Train estimator.\n",
    "estimator_lin = tf.estimator.Estimator(\n",
    "    make_model_fn_precision_at_recall(feature_columns), model_dir=model_dir)\n",
    "estimator_lin.train(train_input_fn, steps=250) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-08T11:33:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tfco_tmp/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.38415s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-08-11:33:37\n",
      "INFO:tensorflow:Saving dict for global step 250: Precision-At-Recall = 0.99945563, global_step = 250, loss = 0.5915339\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: tfco_tmp/model.ckpt-250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Precision-At-Recall': 0.99945563, 'loss': 0.5915339, 'global_step': 250}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_lin.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2d) Recall_At_Precision Training with Custom Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_fn_recall_at_precision(feature_columns):\n",
    "  # Returns model_fn.\n",
    "\n",
    "  def model_fn(features, labels, mode):\n",
    "    # Create model from features.\n",
    "    layers = []\n",
    "    layers.append(tf.keras.layers.DenseFeatures(feature_columns))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    logits = model(features)\n",
    "\n",
    "    # Baseline cross-entropy loss.\n",
    "    baseline_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    baseline_loss = baseline_loss_fn(labels, logits)\n",
    "\n",
    "    # As a slight variant from the above previous training, we will optimize a \n",
    "    # weighted combination of Precision At Recall and the baseline loss.\n",
    "    baseline_coef = 0.2\n",
    "    \n",
    "    train_op = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      # Set up ROC-AUC optimization problem.\n",
    "      # Create context with labels and predictions.\n",
    "      context = tfco.rate_context(logits, labels)\n",
    "\n",
    "      # Create optimization problem with Recall-At-Precision as the objective. The library\n",
    "      # expects a minimization objective, so we negate the Recall-At-Precision. We optimize\n",
    "      # a convex combination of (negative) Recall-At-Precision and the baseline loss (wrapped\n",
    "      # in a rate object).\n",
    "      recall_at_precision_rate = tfco.recall_at_precision(\n",
    "          context, precision_target=0.9, penalty_loss=tfco.SoftmaxCrossEntropyLoss())\n",
    "      problem = tfco.RateMinimizationProblem(\n",
    "          (1 - baseline_coef) * (-recall_at_precision_rate) + \n",
    "          baseline_coef * tfco.wrap_rate(baseline_loss))\n",
    "\n",
    "      # Create Lagrangian loss for `problem`. What we get back is a loss \n",
    "      # function, a nullary function that returns a list of update_ops that \n",
    "      # need to be run before every gradient update, and the Lagrange \n",
    "      # multipliers maintained internally by the loss.\n",
    "      # The argument `dual_scale` is a hyper-parameter that specifies the  \n",
    "      # relative importance placed on updates on the Lagrange multipliers.\n",
    "      loss_fn, update_ops_fn, multipliers = tfco.create_lagrangian_loss(\n",
    "          problem, dual_scale=1.0)\n",
    "      \n",
    "      # Set up optimizer and the list of variables to optimize the loss.\n",
    "      optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "      optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
    "      \n",
    "      # Get minimize op and group with update_ops.\n",
    "      var_list = (\n",
    "          model.trainable_weights + problem.trainable_variables + [multipliers])\n",
    "      minimize_op = optimizer.get_updates(loss_fn(), var_list)\n",
    "      update_ops = update_ops_fn()\n",
    "      train_op = tf.group(*update_ops, minimize_op)\n",
    "\n",
    "    # Evaluate Recall At Precision.\n",
    "    recall_at_precision_metric = tf.keras.metrics.RecallAtPrecision(0.6)\n",
    "    recall_at_precision_metric.update_state(labels, tf.sigmoid(logits))\n",
    "\n",
    "    # We do not use the Lagrangian loss for evaluation/bookkeeping\n",
    "    # purposes as it depends on some internal variables that may not be\n",
    "    # set properly during evaluation time. We instead pass loss=baseline_loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        predictions=logits, \n",
    "        loss=baseline_loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'Recall-At-Precision': recall_at_precision_metric})\n",
    "    \n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tfco_tmp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.8522432, step = 0\n",
      "INFO:tensorflow:global_step/sec: 375.598\n",
      "INFO:tensorflow:loss = 0.25577545, step = 100 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.939\n",
      "INFO:tensorflow:loss = 0.21658714, step = 200 (0.104 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 250...\n",
      "INFO:tensorflow:Saving checkpoints for 250 into tfco_tmp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 250...\n",
      "INFO:tensorflow:Loss for final step: 0.20634533.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7fa41239e190>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary model directory.\n",
    "model_dir = \"tfco_tmp\"\n",
    "if os.path.exists(model_dir):\n",
    "  shutil.rmtree(model_dir)\n",
    "\n",
    "# Train estimator.\n",
    "estimator_lin = tf.estimator.Estimator(\n",
    "    make_model_fn_recall_at_precision(feature_columns), model_dir=model_dir)\n",
    "estimator_lin.train(train_input_fn, steps=250) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'STATEID': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'DISTID': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'PSUID': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'SCHOOLID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'SQGOVT': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'SS1': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'SS3': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'SS4': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'SS5': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'SS6': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'SS7': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'SS8': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'SS9': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'SS10': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'SS11': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'SS12': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'SS13': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-10-08T11:33:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tfco_tmp/model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.35913s\n",
      "INFO:tensorflow:Finished evaluation at 2020-10-08-11:33:40\n",
      "INFO:tensorflow:Saving dict for global step 250: Recall-At-Precision = 1.0, global_step = 250, loss = 0.19825907\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: tfco_tmp/model.ckpt-250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Recall-At-Precision': 1.0, 'loss': 0.19825907, 'global_step': 250}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_lin.evaluate(test_input_fn)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PRAUC_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

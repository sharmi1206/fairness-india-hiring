{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_61ALUMiPGz"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Constrained Optimization Authors. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIpuAlVyicwB"
   },
   "source": [
    "## Problem Setup\n",
    "\n",
    "This is a simple example of recall-constrained optimization on simulated data: we seek a classifier that minimizes the average hinge loss while constraining recall to be at least 90%.\n",
    "\n",
    "We'll start with the required imports&mdash;notice the definition of `tfco`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PXL-Tkcip04"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wj8ptvZiuCz"
   },
   "source": [
    "We load the [https://www.researchconnections.org/icpsrweb/instructors/studies/36151] and do some pre-processing. The dataset is based on India's Human Development Survey, is to predict whether someone who has higher education is appointed as a teaching staff or not. We construct three protected groups, two based on gender (SS7 - Male and Female) and two based on religion (SS11- Hindu, Muslim, Christian, Sikh, Tribal, etc) and on Jati Code (SS12 - Brahmi, Forward Class or Backward Class OBSC, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GitHub version of TFCO\n",
    "#!pip install git+https://github.com/google-research/tensorflow_constrained_optimization.git\n",
    "import tensorflow_constrained_optimization as tfco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DISTID</th>\n",
       "      <th>PSUID</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>SQGOVT</th>\n",
       "      <th>SS1</th>\n",
       "      <th>SS3</th>\n",
       "      <th>SS4</th>\n",
       "      <th>SS5</th>\n",
       "      <th>SS6</th>\n",
       "      <th>SS7</th>\n",
       "      <th>SS8</th>\n",
       "      <th>SS9</th>\n",
       "      <th>SS10</th>\n",
       "      <th>SS11</th>\n",
       "      <th>SS12</th>\n",
       "      <th>SS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEID  DISTID  PSUID  SCHOOLID  SQGOVT SS1 SS3 SS4 SS5 SS6 SS7 SS8 SS9  \\\n",
       "0        1       2      1         1       1   1   1   1   5   1   1  25  15   \n",
       "1        1       2      1         1       1   2   2   3   5   1   2  26  15   \n",
       "2        1       2      1         1       1   3   3   3  99   1   2  35   0   \n",
       "3        1       2      1         2       2   1   1   3   2   2   2  25  15   \n",
       "4        1       2      1         2       2   2   2   1   2   1   2  21  15   \n",
       "\n",
       "  SS10 SS11 SS12 SS13  \n",
       "0    1    2    3    2  \n",
       "1    1    2    3    2  \n",
       "2         2    5    0  \n",
       "3    0    2    3    4  \n",
       "4    0    2    3    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"data/staffing-teaching/School-Staff-Data.csv\"\n",
    "\n",
    "# Read dataset from the UCI web repository and assign column names.\n",
    "data_df = pd.read_csv(dataset_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names in the dataset.\n",
    "cols = data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543898"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS1\n",
      "{'1': 1.0, '2': 12.0, '3': 23.0, '4': 34.0, '5': 42.0, '6': 43.0, '7': 44.0, '8': 45.0, '9': 46.0, '10': 2.0, '11': 3.0, '12': 4.0, '13': 5.0, '14': 6.0, '15': 7.0, '16': 8.0, '17': 9.0, '18': 10.0, '19': 11.0, '20': 13.0, '21': 14.0, '22': 15.0, '23': 16.0, '24': 17.0, '25': 18.0, '26': 19.0, '27': 20.0, '28': 21.0, '29': 22.0, '30': 24.0, '31': 25.0, '32': 26.0, '33': 27.0, '34': 28.0, '35': 29.0, '36': 30.0, '37': 31.0, '38': 32.0, '39': 33.0, '40': 35.0, '41': 36.0, '42': 37.0, '43': 38.0, '44': 39.0, '45': 40.0, '46': 41.0, ' ': 0.0}\n",
      "SS3\n",
      "{'1': 1.0, '2': 2.0, '3': 3.0, '5': 5.0, '4': 4.0, ' ': 0.0}\n",
      "SS4\n",
      "{'1': 1.0, '3': 3.0, '2': 2.0, ' ': 0.0}\n",
      "SS5\n",
      "{'5': 9.0, '99': 15.0, '2': 5.0, '4': 8.0, '3': 7.0, '8': 13.0, '6': 11.0, '1': 1.0, '10': 2.0, '55': 10.0, '12': 4.0, '9': 14.0, '7': 12.0, ' ': 0.0, '11': 3.0, '22': 6.0}\n",
      "SS6\n",
      "{'1': 1.0, '2': 2.0, ' ': 0.0, '3': 3.0}\n",
      "SS7\n",
      "{'1': 1.0, '2': 2.0, ' ': 0.0}\n",
      "SS8\n",
      "{'25': 12.0, '26': 13.0, '35': 22.0, '21': 8.0, '32': 19.0, '27': 14.0, '24': 11.0, '34': 21.0, '44': 31.0, '30': 17.0, '28': 15.0, '48': 35.0, '63': 50.0, '55': 42.0, '42': 29.0, '33': 20.0, '37': 24.0, '40': 27.0, '72': 59.0, '39': 26.0, '43': 30.0, '22': 9.0, '51': 38.0, '36': 23.0, '45': 32.0, '47': 34.0, '29': 16.0, '65': 52.0, '23': 10.0, '20': 7.0, '19': 6.0, '56': 43.0, '50': 37.0, '52': 39.0, '57': 44.0, '53': 40.0, '31': 18.0, '49': 36.0, '46': 33.0, '58': 45.0, '38': 25.0, '18': 5.0, '61': 48.0, '60': 47.0, '62': 49.0, '41': 28.0, '54': 41.0, '68': 55.0, '80': 66.0, '67': 54.0, '59': 46.0, '70': 57.0, '76': 63.0, '71': 58.0, '66': 53.0, '74': 61.0, '17': 4.0, ' ': 0.0, '75': 62.0, '16': 3.0, '73': 60.0, '15': 2.0, '64': 51.0, '8': 65.0, '69': 56.0, '79': 64.0, '82': 67.0, '14': 1.0}\n",
      "SS9\n",
      "{'15': 4.0, '0': 1.0, '17': 5.0, '12': 3.0, '10': 2.0, '5': 6.0, '8': 7.0, ' ': 0.0}\n",
      "SS10\n",
      "{'1': 2.0, ' ': 0.0, '0': 1.0}\n",
      "SS11\n",
      "{'2': 2.0, '1': 1.0, '3': 3.0, ' ': 0.0, '4': 4.0, '5': 5.0, '6': 6.0, '9': 9.0, '8': 8.0, '7': 7.0}\n",
      "SS12\n",
      "{'3': 3.0, '5': 5.0, '2': 2.0, ' ': 0.0, '6': 6.0, '1': 1.0, '4': 4.0}\n",
      "SS13\n",
      "{'2': 13.0, '0': 1.0, '4': 35.0, '1': 2.0, '5': 43.0, '12': 5.0, '35': 30.0, '3': 24.0, '7': 57.0, '10': 3.0, '8': 62.0, '9': 66.0, '21': 15.0, '14': 7.0, '11': 4.0, '13': 6.0, '6': 51.0, ' ': 0.0, '80': 63.0, '45': 39.0, '17': 10.0, '60': 52.0, '18': 11.0, '90': 67.0, '20': 14.0, '25': 19.0, '15': 8.0, '30': 25.0, '16': 9.0, '40': 36.0, '26': 20.0, '22': 16.0, '31': 26.0, '50': 44.0, '99': 68.0, '33': 28.0, '28': 22.0, '19': 12.0, '23': 17.0, '27': 21.0, '82': 64.0, '24': 18.0, '38': 33.0, '46': 40.0, '39': 34.0, '75': 61.0, '70': 58.0, '56': 49.0, '63': 54.0, '32': 27.0, '34': 29.0, '55': 48.0, '42': 37.0, '37': 32.0, '36': 31.0, '54': 47.0, '65': 55.0, '48': 42.0, '73': 60.0, '47': 41.0, '53': 46.0, '72': 59.0, '52': 45.0, '85': 65.0, '58': 50.0, '62': 53.0, '43': 38.0, '66': 56.0, '29': 23.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DISTID</th>\n",
       "      <th>PSUID</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>SQGOVT</th>\n",
       "      <th>SS1</th>\n",
       "      <th>SS3</th>\n",
       "      <th>SS4</th>\n",
       "      <th>SS5</th>\n",
       "      <th>SS6</th>\n",
       "      <th>SS7</th>\n",
       "      <th>SS8</th>\n",
       "      <th>SS9</th>\n",
       "      <th>SS10</th>\n",
       "      <th>SS11</th>\n",
       "      <th>SS12</th>\n",
       "      <th>SS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEID  DISTID  PSUID  SCHOOLID  SQGOVT   SS1  SS3  SS4   SS5  SS6  SS7  \\\n",
       "0        1       2      1         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "1        1       2      1         1       1  12.0  2.0  3.0   9.0  1.0  2.0   \n",
       "2        1       2      1         1       1  23.0  3.0  3.0  15.0  1.0  2.0   \n",
       "3        1       2      1         2       2   1.0  1.0  3.0   5.0  2.0  2.0   \n",
       "4        1       2      1         2       2  12.0  2.0  1.0   5.0  1.0  2.0   \n",
       "5        1       2      2         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "6        1       2      2         1       1  12.0  2.0  2.0   9.0  1.0  2.0   \n",
       "7        1       2      2         2       2   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "8        1       2      2         2       2  12.0  2.0  3.0   9.0  1.0  1.0   \n",
       "9        1       2      2         2       2  23.0  2.0  3.0   9.0  1.0  1.0   \n",
       "\n",
       "    SS8  SS9  SS10  SS11  SS12  SS13  \n",
       "0  12.0  4.0   2.0   2.0   3.0  13.0  \n",
       "1  13.0  4.0   2.0   2.0   3.0  13.0  \n",
       "2  22.0  1.0   0.0   2.0   5.0   1.0  \n",
       "3  12.0  4.0   1.0   2.0   3.0  35.0  \n",
       "4   8.0  4.0   1.0   2.0   3.0   2.0  \n",
       "5  22.0  5.0   2.0   2.0   2.0  43.0  \n",
       "6  19.0  5.0   2.0   2.0   2.0   2.0  \n",
       "7  14.0  4.0   2.0   2.0   2.0   1.0  \n",
       "8  11.0  4.0   2.0   2.0   2.0   1.0  \n",
       "9  21.0  3.0   1.0   2.0   2.0   1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data_df.select_dtypes(include=[object]):\n",
    "\n",
    "    data_df['org_'+col] =  data_df[col]\n",
    "    data_df[col] = data_df[col].astype('category').cat.codes\n",
    "    data_df[col] = data_df[col].astype(float)\n",
    "    print(col)\n",
    "    print(dict(zip( data_df['org_'+ col], data_df[col] ) ))\n",
    "\n",
    "\n",
    "data_df = data_df[cols]\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['SS9'] = data_df['SS9'].astype(int)\n",
    "data_df['SS9'] = np.where((data_df['SS9'] != 5), 0, 1)\n",
    "data_df['SS9'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = data_df['SS9'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "31989    0\n",
       "31990    0\n",
       "31991    0\n",
       "31992    0\n",
       "31993    0\n",
       "Name: SS9, Length: 31994, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543898"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = data_df.columns\n",
    "for feature_name in feature_names:  \n",
    "    # Which rows have missing values?\n",
    "    missing_rows = data_df[feature_name].isna()\n",
    "    if missing_rows.any():  # Check if at least one row has a missing value.\n",
    "        data_df[feature_name].fillna(0.0, inplace=True)  # Fill NaN with 0.\n",
    "        missing_rows.rename(feature_name + \"_is_missing\", inplace=True)\n",
    "        data_df = data_df.join(missing_rows)  # Append \"is_missing\" featur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATEID</th>\n",
       "      <th>DISTID</th>\n",
       "      <th>PSUID</th>\n",
       "      <th>SCHOOLID</th>\n",
       "      <th>SQGOVT</th>\n",
       "      <th>SS1</th>\n",
       "      <th>SS3</th>\n",
       "      <th>SS4</th>\n",
       "      <th>SS5</th>\n",
       "      <th>SS6</th>\n",
       "      <th>SS7</th>\n",
       "      <th>SS8</th>\n",
       "      <th>SS9</th>\n",
       "      <th>SS10</th>\n",
       "      <th>SS11</th>\n",
       "      <th>SS12</th>\n",
       "      <th>SS13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATEID  DISTID  PSUID  SCHOOLID  SQGOVT   SS1  SS3  SS4   SS5  SS6  SS7  \\\n",
       "0        1       2      1         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "1        1       2      1         1       1  12.0  2.0  3.0   9.0  1.0  2.0   \n",
       "2        1       2      1         1       1  23.0  3.0  3.0  15.0  1.0  2.0   \n",
       "3        1       2      1         2       2   1.0  1.0  3.0   5.0  2.0  2.0   \n",
       "4        1       2      1         2       2  12.0  2.0  1.0   5.0  1.0  2.0   \n",
       "5        1       2      2         1       1   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "6        1       2      2         1       1  12.0  2.0  2.0   9.0  1.0  2.0   \n",
       "7        1       2      2         2       2   1.0  1.0  1.0   9.0  1.0  1.0   \n",
       "8        1       2      2         2       2  12.0  2.0  3.0   9.0  1.0  1.0   \n",
       "9        1       2      2         2       2  23.0  2.0  3.0   9.0  1.0  1.0   \n",
       "\n",
       "    SS8  SS9  SS10  SS11  SS12  SS13  \n",
       "0  12.0    0   2.0   2.0   3.0  13.0  \n",
       "1  13.0    0   2.0   2.0   3.0  13.0  \n",
       "2  22.0    0   0.0   2.0   5.0   1.0  \n",
       "3  12.0    0   1.0   2.0   3.0  35.0  \n",
       "4   8.0    0   1.0   2.0   3.0   2.0  \n",
       "5  22.0    1   2.0   2.0   2.0  43.0  \n",
       "6  19.0    1   2.0   2.0   2.0   2.0  \n",
       "7  14.0    0   2.0   2.0   2.0   1.0  \n",
       "8  11.0    0   2.0   2.0   2.0   1.0  \n",
       "9  21.0    0   1.0   2.0   2.0   1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data_df.select_dtypes(include=[object]):\n",
    "\n",
    "    data_df['org_'+col] =  data_df[col]\n",
    "    data_df[col] = data_df[col].astype('category').cat.codes\n",
    "    data_df[col] = data_df[col].astype(float)\n",
    "    print(col)\n",
    "    print(dict(zip( data_df['org_'+ col], data_df[col] ) ))\n",
    "\n",
    "\n",
    "data_df = data_df[cols]\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed so that the results are reproducible.\n",
    "np.random.seed(123456)\n",
    "\n",
    "# Train and test indices.\n",
    "train_indices, test_indices = model_selection.train_test_split(\n",
    "    np.arange(data_df.shape[0]), test_size=1./3.)\n",
    "\n",
    "# Train and test data.\n",
    "x_train_df = data_df.loc[train_indices].astype(np.float32)\n",
    "y_train_df = labels_df.loc[train_indices].astype(np.float32)\n",
    "x_test_df = data_df.loc[test_indices].astype(np.float32)\n",
    "y_test_df = labels_df.loc[test_indices].astype(np.float32)\n",
    "\n",
    "# Convert data frames to NumPy arrays.\n",
    "x_train = x_train_df.values\n",
    "y_train = y_train_df.values\n",
    "x_test = x_test_df.values\n",
    "y_test = y_test_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TJcpwqpjOLt"
   },
   "source": [
    "We're almost ready to construct and train our model, but first we'll create a couple of functions to measure performance. We're interested in two quantities: the average hinge loss (which we seek to minimize), and the recall (which we constrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGikzQ0fjSg7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def average_hinge_loss(labels, predictions):\n",
    "  # Recall that the labels are binary (0 or 1).\n",
    "    signed_labels = (labels * 2) - 1\n",
    "    return np.mean(np.maximum(0.0, 1.0 - signed_labels * predictions))\n",
    "\n",
    "def constrained_recall(labels, predictions, pred_labels): #tp/tp+fn\n",
    "  # Recall that the labels are binary (0 or 1).\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    positive_count = np.sum(labels)\n",
    "    negative_count = len(labels) - np.sum(labels)\n",
    "    true_positives = labels * (predictions > 0)\n",
    "    true_positive_count = np.sum(true_positives)\n",
    "    \n",
    "  #compute tp, tp_and_fn and tp_and_fp w.r.t all classes\n",
    "    tp_and_fn = cm.sum(1)\n",
    "    tp = cm.diagonal()\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    tp_and_fp  = fp + tp\n",
    "\n",
    "    precision = tp / tp_and_fp\n",
    "    recall = tp / tp_and_fn\n",
    "    \n",
    "    #print(precision)\n",
    "    #print(recall)\n",
    "    \n",
    "    return recall  #true_positive_count / negative_count\n",
    "\n",
    "\n",
    "def constrained_precision(labels, predictions, pred_labels): #tp/tp+fp\n",
    "  # Precision that the labels are binary (0 or 1).\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    positive_count = np.sum(labels)\n",
    "    tp = cm.diagonal()\n",
    "    true_positives = labels * (predictions > 0)\n",
    "    \n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    tp_and_fp  = fp + tp\n",
    "    \n",
    "    true_positive_count = np.sum(true_positives)\n",
    "\n",
    "   #compute tp, tp_and_fn and tp_and_fp w.r.t all classes\n",
    "    tp_and_fn = cm.sum(1)\n",
    "    \n",
    "\n",
    "    precision = tp / tp_and_fp\n",
    "    recall = tp / tp_and_fn\n",
    "    \n",
    "    #print(precision, tp, tp_and_fp)\n",
    "    #print(recall)\n",
    "\n",
    "    return precision  #true_positive_count / positive_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-h9cRzOjkFH0"
   },
   "source": [
    "## Constructing and Optimizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJL8aqDomWgT"
   },
   "source": [
    "The first step is to create the [KerasPlaceholder](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/tensorflow_constrained_optimization/python/rates/keras.py)s that we'll need. Even in eager mode, these objects act similarly to graph-mode placeholders, in that they initially contain no values, but will be filled-in later (when the Keras loss function is called).\n",
    "\n",
    "They're parameterized by a function that takes the same parameters as a Keras loss function (prediction and labels), and returns the Tensor that the placeholder should represent. In this case, tfco_predictions returns the predictions themselves, and tfco_labels returns the labels themselves, but in more complex settings, one might need to extract multiple different quantities (e.g. protected class information, the predictions of a baseline model, etc.) from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y5h0YZGmh-0G"
   },
   "outputs": [],
   "source": [
    "tfco_predictions = tfco.KerasPlaceholder(lambda _, y_pred: y_pred)\n",
    "tfco_labels = tfco.KerasPlaceholder(lambda y_true, _: y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q48ZK621sgNk"
   },
   "source": [
    "The main motivation of TFCO is to make it easy to create and optimize constrained problems written in terms of linear combinations of *rates*, where a \"rate\" is the proportion of training examples on which an event occurs (e.g. the false positive rate, which is the number of negatively-labeled examples on which the model makes a positive prediction, divided by the number of negatively-labeled examples). Our current example (minimizing a hinge relaxation of the error rate subject to a recall constraint) is such a problem.\n",
    "\n",
    "Using the placeholders defined above, we are now able to define the problem to optimize. The [KerasLayer](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/tensorflow_constrained_optimization/python/rates/keras.py) interface is similar to the [RateMinimizationProblem](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/tensorflow_constrained_optimization/python/rates/rate_minimization_problem.py) interface, in that its two main parameters are the expression to minimize, and a list of constraints. Unlike a [RateMinimizationProblem](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/tensorflow_constrained_optimization/python/rates/rate_minimization_problem.py), however, it also requires a list of all placeholders that are required by its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebAR3ER7sdOS"
   },
   "outputs": [],
   "source": [
    "context = tfco.rate_context(predictions=tfco_predictions, labels=tfco_labels)\n",
    "tfco_layer_recall = tfco.KerasLayer(\n",
    "    tfco.error_rate(context), [tfco.recall(context) >= recall_lower_bound],\n",
    "    placeholders=[tfco_predictions, tfco_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpXDN8KWtkGK"
   },
   "source": [
    "A [KerasLayer](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/tensorflow_constrained_optimization/python/rates/keras.py) plays two roles.\n",
    "\n",
    "\n",
    "1.   It defines the optimization problem, in terms of an objective and constraints. To this end, it also contains the loss function that should be passed to Keras' Model.compile() method.\n",
    "2.   It also contains the internal state needed by TFCO. For this reason, it must be included somewhere in the Keras model. It doesn't matter *where* it's included, since from the perspective of the model, it's an identity function. However, it must be included *somewhere*, so that the internal TFCO state will be updated during optimization.\n",
    "\n",
    "We now construct our model. As in [README.md](https://github.com/google-research/tensorflow_constrained_optimization/tree/master/README.md), we're using a linear model with a bias. Notice that we include tfco_layer in the Sequential model, which ensures that the TFCO internal state will be updated during optimization. We also pass tfco_layer.loss to the Model.compile() function, which causes us to optimize the correct constrained objective. The placeholders that we constructed earlier will be filled-in when tfco_layer.loss() is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36958,
     "status": "ok",
     "timestamp": 1597790506569,
     "user": {
      "displayName": "Andrew Cotter",
      "photoUrl": "",
      "userId": "01600804956648002768"
     },
     "user_tz": 420
    },
    "id": "MEUrkxnmPFud",
    "outputId": "3ced817b-c0f4-4507-c3ea-03e0440760be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)   (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,671\n",
      "Trainable params: 1,666\n",
      "Non-trainable params: 5\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 1.0081\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 914us/step - loss: 0.2303\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 871us/step - loss: 0.0023\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 836us/step - loss: 5.9677e-04\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 857us/step - loss: 3.3222e-04\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 855us/step - loss: 2.4331e-04\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 826us/step - loss: 1.8679e-04\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 841us/step - loss: 1.4748e-04\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 841us/step - loss: 1.2709e-04\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 855us/step - loss: 1.0916e-04\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 820us/step - loss: 8.9087e-05\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 839us/step - loss: 8.3524e-05\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 846us/step - loss: 7.9826e-05\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 839us/step - loss: 7.2563e-05\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 888us/step - loss: 6.0345e-05\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 940us/step - loss: 5.0859e-05\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 926us/step - loss: 5.2470e-05\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 868us/step - loss: 4.1939e-05\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 879us/step - loss: 3.8165e-05\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 884us/step - loss: 3.1492e-05\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 874us/step - loss: 2.4805e-05\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 997us/step - loss: 2.7861e-05\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 2.6351e-05\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 2.1964e-05\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 939us/step - loss: 1.5449e-05\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 941us/step - loss: 1.0915e-05\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 923us/step - loss: 1.4505e-05\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 917us/step - loss: 8.8046e-06\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 1.1322e-05\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 9.8003e-06\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 7.1663e-06\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 0s 896us/step - loss: 5.1411e-06\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 857us/step - loss: 5.3647e-06\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 823us/step - loss: 3.0289e-06\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 868us/step - loss: 8.2187e-07\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 946us/step - loss: 4.8114e-07\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 887us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 864us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 967us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 857us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 847us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 873us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 910us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 893us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 965us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 929us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 878us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 847us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 836us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 772us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 762us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 856us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 969us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 939us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 965us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 890us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 834us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "167/167 [==============================] - 0s 942us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 0s 964us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 848us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 893us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 940us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 766us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 950us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 999us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "[0 0 0 ... 0 0 0] [0. 0. 0. ... 0. 0. 0.]\n",
      "Precision = [0.78687295 0.        ]\n",
      "Recall= [1. 0.]\n",
      "F1 Score = [0.88072624 0.        ]\n",
      "Accuracy0.7868729488982653\n"
     ]
    }
   ],
   "source": [
    "# You can put the tfco.KerasLayer anywhere in the sequence--its only purpose is\n",
    "# to contain the slack variables, denominators, Lagrange multipliers, and loss.\n",
    "# It's a NO-OP (more accurately, an identity function) as far as the model is\n",
    "# concerned.\n",
    "layers = []\n",
    "layers.append(tf.keras.Input(shape=(x_train.shape[-1],)))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(1))\n",
    "layers.append(tfco_layer_recall)\n",
    "model = tf.keras.Sequential(layers)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(1, activation=None, input_shape=(dimension,)),\n",
    "#     tfco_layer\n",
    "# ])\n",
    "model.summary()\n",
    "\n",
    "# Notice that we take the loss function from the tfco.KerasLayer, instead of\n",
    "# using tf.keras.losses.Hinge(), as we did above.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
    "    loss=tfco_layer_recall.loss)\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100)\n",
    "labels = y_test\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(pred_labels, y_test)\n",
    "\n",
    "\n",
    "\n",
    "precisions, recall, f1_score, true_sum = metrics.precision_recall_fscore_support(y_test, pred_labels)\n",
    "\n",
    "print(\"Precision =\", precisions)\n",
    "print(\"Recall=\", recall)\n",
    "print(\"F1 Score =\", f1_score)\n",
    "accuracy_score = metrics.accuracy_score(y_test, pred_labels)\n",
    "print('Accuracy' + str(accuracy_score))\n",
    "\n",
    "\n",
    "trained_predictions = np.ndarray.flatten(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10665,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10665,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(labels))\n",
    "np.shape(trained_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained recall =  [1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "print(\"Constrained recall = \", constrained_recall(labels, trained_predictions, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained average hinge loss = 0.000367\n"
     ]
    }
   ],
   "source": [
    "print(\"Constrained average hinge loss = %f\" %\n",
    "      average_hinge_loss(labels, trained_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aG1eeGIvkl7D"
   },
   "source": [
    "As we hoped, the recall is extremely close to 90%&mdash;and, thanks to the fact that the optimizer uses a (hinge) proxy constraint only when needed, and the actual (zero-one) constraint whenever possible, this is the *true* recall, not a hinge approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SU9jymGjqf7"
   },
   "source": [
    "### Unconstrained Model\n",
    "\n",
    "For comparison, let's try optimizing the same problem *without* the recall constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58243,
     "status": "ok",
     "timestamp": 1597790527866,
     "user": {
      "displayName": "Andrew Cotter",
      "photoUrl": "",
      "userId": "01600804956648002768"
     },
     "user_tz": 420
    },
    "id": "89xgIF7fadOo",
    "outputId": "49800743-b209-4657-a8b6-8365188ac606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,665\n",
      "Trainable params: 1,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 0s 770us/step - loss: 0.5477\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 625us/step - loss: 0.4322\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 560us/step - loss: 0.4235\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 534us/step - loss: 0.4165\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 551us/step - loss: 0.4001\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 539us/step - loss: 0.3583\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 622us/step - loss: 0.0786\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 816us/step - loss: 6.0171e-04\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 668us/step - loss: 1.8416e-04\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 663us/step - loss: 8.6879e-05\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 767us/step - loss: 6.8195e-05\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 754us/step - loss: 4.5335e-05\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 715us/step - loss: 3.1514e-05\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 773us/step - loss: 1.8125e-05\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 864us/step - loss: 1.5893e-05\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 856us/step - loss: 1.8324e-05\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 795us/step - loss: 1.1046e-05\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 781us/step - loss: 1.2474e-06\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 851us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 745us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 720us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 714us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 772us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 670us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 649us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 584us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 0s 602us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 0s 588us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 613us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 0s 684us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 0s 761us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 758us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 0s 735us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 694us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 0s 652us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 744us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 677us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 0s 634us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 0s 613us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 626us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 0s 666us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 0s 625us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 0s 705us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 0s 694us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 0s 577us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 0s 534us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 541us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 0s 633us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 0s 664us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 0s 562us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 0s 536us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 0s 631us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 0s 692us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 0s 707us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 0s 632us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 0s 740us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 0s 713us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 0s 634us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 0s 587us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 0s 654us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 0s 669us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 0s 651us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 0s 697us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 0s 603us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 0s 588us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 0s 568us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "167/167 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "167/167 [==============================] - 0s 591us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "167/167 [==============================] - 0s 596us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "167/167 [==============================] - 0s 665us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "167/167 [==============================] - 0s 732us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "167/167 [==============================] - 0s 623us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "167/167 [==============================] - 0s 560us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "167/167 [==============================] - 0s 569us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "167/167 [==============================] - 0s 637us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "167/167 [==============================] - 0s 613us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s 571us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "167/167 [==============================] - 0s 524us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "167/167 [==============================] - 0s 531us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "167/167 [==============================] - 0s 555us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "167/167 [==============================] - 0s 579us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "167/167 [==============================] - 0s 539us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "167/167 [==============================] - 0s 539us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "167/167 [==============================] - 0s 662us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "167/167 [==============================] - 0s 598us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "167/167 [==============================] - 0s 546us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "167/167 [==============================] - 0s 556us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "167/167 [==============================] - 0s 662us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "167/167 [==============================] - 0s 598us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "167/167 [==============================] - 0s 569us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "167/167 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "167/167 [==============================] - 0s 620us/step - loss: 0.0000e+00\n",
      "[0 0 0 ... 0 0 0] [0. 0. 0. ... 0. 0. 0.]\n",
      "Precision = [0.78687295 0.        ]\n",
      "Recall= [1. 0.]\n",
      "F1 Score = [0.88072624 0.        ]\n",
      "Accuracy0.7868729488982653\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "layers.append(tf.keras.Input(shape=(x_train.shape[-1],)))\n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(32, activation='relu')) \n",
    "layers.append(tf.keras.layers.Dense(1))\n",
    "model = tf.keras.Sequential(layers)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Notice that we take the loss function from the tfco.KerasLayer, instead of\n",
    "# using tf.keras.losses.Hinge(), as we did above.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=.1),\n",
    "    loss=tf.keras.losses.Hinge())\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100)\n",
    "labels = y_test\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(pred_labels, y_test)\n",
    "\n",
    "\n",
    "\n",
    "precisions, recall, f1_score, true_sum = metrics.precision_recall_fscore_support(y_test, pred_labels)\n",
    "\n",
    "print(\"Precision =\", precisions)\n",
    "print(\"Recall=\", recall)\n",
    "print(\"F1 Score =\", f1_score)\n",
    "accuracy_score = metrics.accuracy_score(y_test, pred_labels)\n",
    "print('Accuracy' + str(accuracy_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxL4xf9bkvkj"
   },
   "source": [
    "Because there is no constraint, the unconstrained problem does a better job of minimizing the average hinge loss. To test recall we need a more balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unconstrained average hinge loss = 0.000205\n",
      "Unconstrained recall = [1. 0.]\n",
      "Unconstrained precision = [0.78687295        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "trained_predictions = np.ndarray.flatten(model.predict(x_test))\n",
    "print(\"Unconstrained average hinge loss = %f\" % average_hinge_loss(\n",
    "    labels, trained_predictions))\n",
    "print(\"Unconstrained recall =\", constrained_recall(labels, trained_predictions, pred_labels))\n",
    "print(\"Unconstrained precision =\", constrained_precision(labels, trained_predictions, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Recall_constraint_keras.ipynb",
   "provenance": [
    {
     "file_id": "1KYQ6SqWmq5NcTEMCg9hjT5FshMSdO4Dn",
     "timestamp": 1597790785857
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
